<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Stefan Bruckner </title> <meta name="author" content="Stefan Bruckner"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="visualization, visual analytics, visual computing"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/vca-cubes-logo.svg?48ecacc5769cceff2c3c3d4e9055d4d8"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sbruckner.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <img class="logo" src="/assets/img/vca-cubes-logo.svg"> <span class="font-weight-bold">Stefan</span> Bruckner </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Pokojna-2025-LIT.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Pokojna-2025-LIT.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Pokojna-2025-LIT" class="col-sm-8"> <div class="title">The Language of Infographics: Toward Understanding Conceptual Metaphor Use in Scientific Storytelling</div> <div class="author"> Hana Pokojná, Tobias Isenberg, <em>Stefan Bruckner</em>, Barbora Kozlíková, and Laura Garrison </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2024.3456327" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Pokojna-2025-LIT.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We apply an approach from cognitive linguistics by mapping Conceptual Metaphor Theory (CMT) to the visualization domain to address patterns of visual conceptual metaphors that are often used in science infographics. Metaphors play an essential part in visual communication and are frequently employed to explain complex concepts. However, their use is often based on intuition, rather than following a formal process. At present, we lack tools and language for understanding and describing metaphor use in visualization to the extent where taxonomy and grammar could guide the creation of visual components, e.g., infographics. Our classification of the visual conceptual mappings within scientific representations is based on the breakdown of visual components in existing scientific infographics. We demonstrate the development of this mapping through a detailed analysis of data collected from four domains (biomedicine, climate, space, and anthropology) that represent a diverse range of visual conceptual metaphors used in the visual communication of science. This work allows us to identify patterns of visual conceptual metaphor use within the domains, resolve ambiguities about why specific conceptual metaphors are used, and develop a better overall understanding of visual metaphor use in scientific infographics. Our analysis shows that ontological and orientational conceptual metaphors are the most widely applied to translate complex scientific concepts. To support our findings we developed a visual exploratory tool based on the collected database that places the individual infographics on a spatio-temporal scale and illustrates the breakdown of visual conceptual metaphors.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Vasicek-2025-PEH.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Vasicek-2025-PEH.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Vasicek-2025-PEH" class="col-sm-8"> <div class="title">ProHap Enables Human Proteomic Database Generation Accounting for Population Diversity</div> <div class="author"> Jakub Vašíček, Ksenia G. Kuznetsova, Dafni Skiadopoulou, Lucas Unger, Simona Chera, Luiza M. Ghila, Nuno Bandeira, Pål R. Njølstad, Stefan Johansson, <em>Stefan Bruckner</em>, Lukas Käll, and Marc Vaudel </div> <div class="periodical"> <em>Nature Methods</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1038/s41592-024-02506-0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Vasicek-2025-PEH.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Amid the advances in genomics, the availability of large reference panels of human haplotypes is key to account for human diversity within and across populations. However, mass spectrometry-based proteomics does not benefit from this information. To address this gap, we introduce ProHap, a Python-based tool that constructs protein sequence databases from phased genotypes of reference panels. ProHap enables researchers to account for haplotype diversity in proteomic searches.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bru-2023-LHI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bru-2023-LHI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bru-2023-LHI" class="col-sm-8"> <div class="title">Line Harp: Importance-Driven Sonification for Dense Line Charts</div> <div class="author"> Egil Bru, Thomas Trautner, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Proceedings of IEEE VIS (Short Papers)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/VIS54172.2023.00046" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bru-2023-LHI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Describing the myriad biological processes occurring in living beings over time, the science of physiology is complex and critical to our understanding of how life works. Physiology spans many spatio-temporal scales to combine and bridge from the basic sciences (biology, physics, and chemistry) to medicine. Recent years have seen an explosion of new and finer-grained experimental and acquisition methods to characterize these data. The volume and complexity of these data necessitate effective visualizations to complement standard analysis practice. Visualization approaches must carefully consider and be adaptable to the user’s main task, be it exploratory, analytical, or communication-oriented. This research contributes to the areas of theory, empirical findings, methods, applications, and research replicability in visualizing physiology. Our overarching theme is the cross-disciplinary application of medical illustration and visualization techniques to address challenges in exploring, analyzing, and communicating aspects of human physiology to audiences with differing expertise.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Garrison-2023-CAB.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Garrison-2023-CAB.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Garrison-2023-CAB" class="col-sm-8"> <div class="title">Changing Aesthetics in Biomolecular Graphics</div> <div class="author"> Laura A. Garrison, David S. Goodsell, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>IEEE Computer Graphics and Applications</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/MCG.2023.3250680" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Garrison-2023-CAB.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Aesthetics for the visualization of biomolecular structures have evolved over the years according to technological advances, user needs, and modes of dissemination. In this article, we explore the goals, challenges, and solutions that have shaped the current landscape of biomolecular imagery from the overlapping perspectives of computer science, structural biology, and biomedical illustration. We discuss changing approaches to rendering, color, human–computer interface, and narrative in the development and presentation of biomolecular graphics. With this historical perspective on the evolving styles and trends in each of these areas, we identify opportunities and challenges for future aesthetics in biomolecular graphics that encourage continued collaboration from multiple intersecting fields.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Garrison-2023-CAN.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Garrison-2023-CAN.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Garrison-2023-CAN" class="col-sm-8"> <div class="title">Current Approaches in Narrative Medical Visualization</div> <div class="author"> Laura Ann Garrison, Monique Meuschke, Bernhard Preim, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Approaches for Science Illustration and Communication</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-031-41652-1_4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Garrison-2023-CAN.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In a world increasingly driven by data and technology, it is imperative to empower stakeholders across diverse backgrounds (scientists, policymakers, patients, the general public) to make informed decisions about their health with the information available. However, simply providing the information is often not enough. The key to sharing and communicating health and medicine is making the information relevant to the intended audience. This issue lies at the heart of effective science communication. Storytelling is an age-old practice, and arguably one of the most defining features of humanity. Stories enable science communicators to translate complex information from health and medicine into a narrative that is personally accessible and relevant to the individual. Many pieces come together to craft what many would call a "good story"–one of these is narrative. Our work seeks to tease out the role of narrative, with its various components, in telling medical stories. This chapter discusses current approaches in narrative medical visualization, with an eye toward future opportunities in developing narratives for data-driven medical stories. We explore various strategies in narrative structure and character that may be unique to telling medical stories and provide an outlook on future directions in this space.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Garrison-2023-VEA.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Garrison-2023-VEA.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Garrison-2023-VEA" class="col-sm-8"> <div class="title">Visual Exploration, Analysis, and Communication of Physiological Processes</div> <div class="author"> Laura A. Garrison, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Proceedings of EuroVis (Dirk Bartz Prize)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/evm.20231087" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Garrison-2023-VEA.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Describing the myriad biological processes occurring in living beings over time, the science of physiology is complex and critical to our understanding of how life works. Physiology spans many spatio-temporal scales to combine and bridge from the basic sciences (biology, physics, and chemistry) to medicine. Recent years have seen an explosion of new and finer-grained experimental and acquisition methods to characterize these data. The volume and complexity of these data necessitate effective visualizations to complement standard analysis practice. Visualization approaches must carefully consider and be adaptable to the user’s main task, be it exploratory, analytical, or communication-oriented. This research contributes to the areas of theory, empirical findings, methods, applications, and research replicability in visualizing physiology. Our overarching theme is the cross-disciplinary application of medical illustration and visualization techniques to address challenges in exploring, analyzing, and communicating aspects of human physiology to audiences with differing expertise.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Mittenentzwei-2023-DDS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Mittenentzwei-2023-DDS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Mittenentzwei-2023-DDS" class="col-sm-8"> <div class="title">Do Disease Stories need a Hero? Effects of Human Protagonists on a Narrative Visualization about Cerebral Small Vessel Disease</div> <div class="author"> Sarah Mittenentzwei, Veronika Weiß, Stefanie Schreiber, Laura A. Garrison, <em>Stefan Bruckner</em>, Malte Pfister, Bernhard Preim, and Monique Meuschke </div> <div class="periodical"> <em>Computer Graphics Forum</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.14817" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Mittenentzwei-2023-DDS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Authors use various media formats to convey disease information to a broad audience, from articles and videos to interviews or documentaries. These media often include human characters, such as patients or treating physicians, who are involved with the disease. While artistic media, such as hand-crafted illustrations and animations are used for health communication in many cases, our goal is to focus on data-driven visualizations. Over the last decade, narrative visualization has experienced increasing prominence, employing storytelling techniques to present data in an understandable way. Similar to classic storytelling formats, narrative medical visualizations may also take a human character-centered design approach. However, the impact of this form of data communication on the user is largely unexplored. This study investigates the protagonist’s influence on user experience in terms of engagement, identification, self-referencing, emotional response, perceived credibility, and time spent in the story. Our experimental setup utilizes a character-driven story structure for disease stories derived from Joseph Campbell’s Hero’s Journey. Using this structure, we generated three conditions for a cerebral small vessel disease story that vary by their protagonist: (1) a patient, (2) a physician, and (3) a base condition with no human protagonist. These story variants formed the basis for our hypotheses on the effect of a human protagonist in disease stories, which we evaluated in an online study with 30 participants. Our findings indicate that a human protagonist exerts various influences on the story perception and that these also vary depending on the type of protagonist.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Mittenentzwei-2023-IUB.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Mittenentzwei-2023-IUB.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Mittenentzwei-2023-IUB" class="col-sm-8"> <div class="title">Investigating User Behavior in Slideshows and Scrollytelling as Narrative Genres in Medical Visualization</div> <div class="author"> Sarah Mittenentzwei, Laura A. Garrison, Eric Mörth, Kai Lawonn, <em>Stefan Bruckner</em>, Bernhard Preim, and Monique Meuschke </div> <div class="periodical"> <em>Computers &amp; Graphics</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.cag.2023.06.011" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Mittenentzwei-2023-IUB.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this study, we explore the impact of genre and navigation on user comprehension, preferences, and behaviors when experiencing data-driven disease stories. Our between-subject study (n=85) evaluated these aspects in-the-wild, with results pointing towards some general design considerations to keep in mind when authoring data-driven disease stories. Combining storytelling with interactive new media techniques, narrative medical visualization is a promising approach to communicating topics in medicine to a general audience in an accessible manner. For patients, visual storytelling may help them to better understand medical procedures and treatment options for more informed decision-making, boost their confidence and alleviate anxiety, and promote stronger personal health advocacy. Narrative medical visualization provides the building blocks for producing data-driven disease stories, which may be presented in several visual styles. These different styles correspond to different narrative genres, e.g., a Slideshow. Narrative genres can employ different navigational approaches. For instance, a Slideshow may rely on click interactions to advance through a story, while Scrollytelling typically uses vertical scrolling for navigation. While a common goal of a narrative medical visualization is to encourage a particular behavior, e.g., quitting smoking, it is unclear to what extent the choice of genre influences subsequent user behavior. Our study opens a new research direction into choice of narrative genre on user preferences and behavior in data-driven disease stories.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Moerth-2023-SIV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Moerth-2023-SIV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Moerth-2023-SIV" class="col-sm-8"> <div class="title">ScrollyVis: Interactive Visual Authoring of Guided Dynamic Narratives for Scientific Scrollytelling</div> <div class="author"> Eric Mörth, <em>Stefan Bruckner</em>, and Noeska N. Smit </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2022.3205769" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Moerth-2023-SIV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Visual stories are an effective and powerful tool to convey specific information to a diverse public. Scrollytelling is a recent visual storytelling technique extensively used on the web, where content appears or changes as users scroll up or down a page. By employing the familiar gesture of scrolling as its primary interaction mechanism, it provides users with a sense of control, exploration and discoverability while still offering a simple and intuitive interface. In this paper, we present a novel approach for authoring, editing, and presenting data-driven scientific narratives using scrollytelling. Our method flexibly integrates common sources such as images, text, and video, but also supports more specialized visualization techniques such as interactive maps as well as scalar field and mesh data visualizations. We show that scrolling navigation can be used to traverse dynamic narratives and demonstrate how it can be combined with interactive parameter exploration. The resulting system consists of an extensible web-based authoring tool capable of exporting stand-alone stories that can be hosted on any web server. We demonstrate the power and utility of our approach with case studies from several diverse scientific fields and with a user study including 12 participants of diverse professional backgrounds. Furthermore, an expert in creating interactive articles assessed the usefulness of our approach and the quality of the created stories.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Vasicek-2023-FHS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Vasicek-2023-FHS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Vasicek-2023-FHS" class="col-sm-8"> <div class="title">Finding Haplotypic Signatures in Proteins</div> <div class="author"> Jakub Vašíček, Dafni Skiadopoulou, Ksenia G. Kuznetsova, Bo Wen, Stefan Johansson, Pål R. Njølstad, <em>Stefan Bruckner</em>, Lukas Käll, and Marc Vaudel </div> <div class="periodical"> <em>GigaScience</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1093/gigascience/giad093" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Vasicek-2023-FHS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>The nonrandom distribution of alleles of common genomic variants produces haplotypes, which are fundamental in medical and population genetic studies. Consequently, protein-coding genes with different co-occurring sets of alleles can encode different amino acid sequences: protein haplotypes. These protein haplotypes are present in biological samples and detectable by mass spectrometry, but they are not accounted for in proteomic searches. Consequently, the impact of haplotypic variation on the results of proteomic searches and the discoverability of peptides specific to haplotypes remain unknown. Here, we study how common genetic haplotypes influence the proteomic search space and investigate the possibility to match peptides containing multiple amino acid substitutions to a publicly available data set of mass spectra. We found that for 12.42% of the discoverable amino acid substitutions encoded by common haplotypes, 2 or more substitutions may co-occur in the same peptide after tryptic digestion of the protein haplotypes. We identified 352 spectra that matched to such multivariant peptides, and out of the 4,582 amino acid substitutions identified, 6.37% were covered by multivariant peptides. However, the evaluation of the reliability of these matches remains challenging, suggesting that refined error rate estimation procedures are needed for such complex proteomic searches. As these procedures become available and the ability to analyze protein haplotypes increases, we anticipate that proteomics will provide new information on the consequences of common variation, across tissues and time.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Meuschke-2022-NMV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Meuschke-2022-NMV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Meuschke-2022-NMV" class="col-sm-8"> <div class="title">Narrative Medical Visualization to Communicate Disease Data</div> <div class="author"> Monique Meuschke, Laura A. Garrison, Noeska N. Smit, Benjamin Bach, Sarah Mittenentzwei, Veronika Weiß, <em>Stefan Bruckner</em>, Kai Lawonn, and Bernhard Preim </div> <div class="periodical"> <em>Computers &amp; Graphics</em>, Oct 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.cag.2022.07.017" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Meuschke-2022-NMV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This paper explores narrative techniques combined with medical visualizations to tell data-driven stories about diseases for a general audience. The field of medical illustration uses narrative visualization through hand-crafted techniques to promote health literacy. However, data-driven narrative visualization has rarely been applied to medical data. We derived a template for creating stories about diseases and applied it to three selected diseases to demonstrate how narrative techniques could support visual communication and facilitate understanding of medical data. One of our main considerations is how interactive 3D anatomical models can be integrated into the story and whether this leads to compelling stories in which the users feel involved. A between-subject study with 90 participants suggests that the combination of a carefully designed narrative structure, the constant involvement of a specific patient, high-qualitative visualizations combined with easy-to-use interactions, are critical for an understandable story about diseases that would be remembered by participants.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Eichner-2022-MMI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Eichner-2022-MMI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Eichner-2022-MMI" class="col-sm-8"> <div class="title">MuSIC: Multi-Sequential Interactive Co-Registration for Cancer Imaging Data Based On Segmentation Masks</div> <div class="author"> Tanja Eichner, Eric Mörth, Kari S. Wagner-Larsen, Njål Lura, Ingfrid S. Haldorsen, Eduard Gröller, <em>Stefan Bruckner</em>, and Noeska N. Smit </div> <div class="periodical"> <em>In Proceedings of VCBM</em>, Sep 2022 </div> <div class="periodical"> Best Paper Honorable Mention at VCBM 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/vcbm.20221190" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Eichner-2022-MMI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In gynecologic cancer imaging, multiple magnetic resonance imaging (MRI) sequences are acquired per patient to reveal different tissue characteristics. However, after image acquisition, the anatomical structures can be misaligned in the various sequences due to changing patient location in the scanner and organ movements. The co-registration process aims to align the sequences to allow for multi-sequential tumor imaging analysis. However, automatic co-registration often leads to unsatisfying results. To address this problem, we propose the web-based application MuSIC (Multi-Sequential Interactive Co-registration). The approach allows medical experts to co-register multiple sequences simultaneously based on a pre-defined segmentation mask generated for one of the sequences. Our contributions lie in our proposed workflow. First, a shape matching algorithm based on dual annealing searches for the tumor position in each sequence. The user can then interactively adapt the proposed segmentation positions if needed. During this procedure, we include a multi-modal magic lens visualization for visual quality assessment. Then, we register the volumes based on the segmentation mask positions. We allow for both rigid and deformable registration. Finally, we conducted a usability analysis with seven medical and machine learning experts to verify the utility of our approach. Our participants highly appreciate the multi-sequential setup and see themselves using MuSIC in the future.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Kleinau-2022-TAB.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Kleinau-2022-TAB.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kleinau-2022-TAB" class="col-sm-8"> <div class="title">Is There a Tornado in Alex’s Blood Flow? A Case Study for Narrative Medical Visualization</div> <div class="author"> Anna Kleinau, Evgenia Stupak, Eric Mörth, Laura A. Garrison, Sarah Mittenentzwei, Noeska N. Smit, Kai Lawonn, <em>Stefan Bruckner</em>, Matthias Gutberlet, Bernhard Preim, and Monique Meuschke </div> <div class="periodical"> <em>In Proceedings of VCBM</em>, Sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/vcbm.20221183" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Kleinau-2022-TAB.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Narrative visualization advantageously combines storytelling with new media formats and techniques, like interactivity, to create improved learning experiences. In medicine, it has the potential to improve patient understanding of diagnostic procedures and treatment options, promote confidence, reduce anxiety, and support informed decision-making. However, limited scientific research has been conducted regarding the use of narrative visualization in medicine. To explore the value of narrative visualization in this domain, we introduce a data-driven story to inform a broad audience about the usage of measured blood flow data to diagnose and treat cardiovascular diseases. The focus of the story is on blood flow vortices in the aorta, with which imaging technique they are examined, and why they can be dangerous. In an interdisciplinary team, we define the main contents of the story and the resulting design questions. We sketch the iterative design process and implement the story based on two genres. In a between-subject study, we evaluate the suitability and understandability of the story and the influence of different navigation concepts on user experience. Finally, we discuss reusable concepts for further narrative medical visualization projects.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Trautner-2022-HPV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Trautner-2022-HPV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Trautner-2022-HPV" class="col-sm-8"> <div class="title">Honeycomb Plots: Visual Enhancements for Hexagonal Maps</div> <div class="author"> Thomas Trautner, Maximilian Sbardellati, Sergej Stoppel, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Procedings of VMV</em>, Sep 2022 </div> <div class="periodical"> Best Paper Award at VMV 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/vmv.20221205" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Trautner-2022-HPV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/mU7QFVP3yKQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/TTrautner/HoneycombPlots" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Aggregation through binning is a commonly used technique for visualizing large, dense, and overplotted two-dimensional data sets. However, aggregation can hide nuanced data-distribution features and complicates the display of multiple data-dependent variables, since color mapping is the primary means of encoding. In this paper, we present novel techniques for enhancing hexplots with spatialization cues while avoiding common disadvantages of three-dimensional visualizations. In particular, we focus on techniques relying on preattentive features that exploit shading and shape cues to emphasize relative value differences. Furthermore, we introduce a novel visual encoding that conveys information about the data distributions or trends within individual tiles. Based on multiple usage examples from different domains and real-world scenarios, we generate expressive visualizations that increase the information content of classic hexplots and validate their effectiveness in a user study.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Kristiansen-2022-CLV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Kristiansen-2022-CLV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kristiansen-2022-CLV" class="col-sm-8"> <div class="title">Content-Driven Layout for Visualization Design</div> <div class="author"> Yngve Kristiansen, Laura Garrison, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Proceedings of VINCI</em>, Aug 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3554944.3554950" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Kristiansen-2022-CLV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Multi-view visualizations are typically presented in a grid layout with elements positioned according to their bounding rectangles. These rectangles often contain unused white space. In cases where Tufte’s Shrink Principle can be applied to reduce non-data-ink without impairing the communication of information, unused white space can be utilized for the placement of other elements. This is often done in manually “hand-crafted” layouts by designers. However, upon changes to individual elements, this design process has to be repeated. To reduce non-data-ink and repetitive manual design, we contribute a method for automatically turning a grid layout into a content-driven layout, where elements are positioned with respect to their contents. Existing approaches have explored the use of a force simulation in conjunction with proxy geometries to simplify collision handling for irregular shapes. Such customized force directed layouts are usually unstable, and often require additional constraints to run properly. In addition, proxy geometries become less accurate and effective with more irregular shapes. To solve these shortcomings, we contribute an approach for identifying central elements in an original grid layout in order to set up corresponding attractive forces. Furthermore, we utilize an imagebased approach for collision detection and avoidance that works accurately for highly irregular shapes. We demonstrate the utility of our approach with three case studies.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Moerth-2022-IIC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Moerth-2022-IIC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Moerth-2022-IIC" class="col-sm-8"> <div class="title">Icevis: Interactive Clustering Exploration for Tumor Sub-Region Analysis in Multiparametric Cancer Imaging</div> <div class="author"> Eric Mörth, Tanja Eichner, Haldorsen Ingfrid, <em>Stefan Bruckner</em>, and Noeska N. Smit </div> <div class="periodical"> <em>In Proceedings of VINCI (Short Papers)</em>, Aug 2022 </div> <div class="periodical"> Best Short Paper Award at VINCI 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3554944.3554958" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Moerth-2022-IIC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Tumor tissue characteristics derived from imaging data are gaining importance in clinical research. Tumor sub-regions may play a critical role in defining tumor types and may hold essential information about tumor aggressiveness. Depending on the tumor’s location within the body, such sub-regions can be easily identified and determined by physiology, but these sub-regions are not readily visible to others. Regions within a tumor are currently explored by comparing the image sequences and analyzing the tissue heterogeneity present. To improve the exploration of such tumor sub-regions, we propose a visual analytics tool called ICEVis. ICEVis supports the identification of tumor sub-regions and corresponding features combined with cluster visualizations highlighting cluster validity. It is often difficult to estimate the optimal number of clusters; we provide rich facilities to support this task, incorporating various statistical measures and interactive exploration of the results. We evaluated our tool with three clinical researchers to show the potential of our approach.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Garrison-2022-CBP.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Garrison-2022-CBP.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Garrison-2022-CBP" class="col-sm-8"> <div class="title">Considering Best Practices in Color Palettes for Molecular Visualizations</div> <div class="author"> Laura A. Garrison, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Journal of Integrative Bioinformatics</em>, Jun 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1515/jib-2022-0016" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Garrison-2022-CBP.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Biomedical illustration and visualization techniques provide a window into complex molecular worlds that are difficult to capture through experimental means alone. Biomedical illustrators frequently employ color to help tell a molecular story, e.g., to identify key molecules in a signaling pathway. Currently, color use for molecules is largely arbitrary and often chosen based on the client, cultural factors, or personal taste. The study of molecular dynamics is relatively young, and some stakeholders argue that color use guidelines would throttle the growth of the field. Instead, content authors have ample creative freedom to choose an aesthetic that, e.g., supports the story they want to tell. However, such creative freedom comes at a price. The color design process is challenging, particularly for those without a background in color theory. The result is a semantically inconsistent color space that reduces the interpretability and effectiveness of molecular visualizations as a whole. Our contribution in this paper is threefold. We first discuss some of the factors that contribute to this array of color palettes. Second, we provide a brief sampling of color palettes used in both industry and research sectors. Lastly, we suggest considerations for developing best practices around color palettes applied to molecular visualization.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Garrison-2022-TOV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Garrison-2022-TOV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Garrison-2022-TOV" class="col-sm-8"> <div class="title">Trends &amp; Opportunities in Visualization for Physiology: A Multiscale Overview</div> <div class="author"> Laura A. Garrison, Ivan Kolesar, Ivan Viola, Helwig Hauser, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Jun 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.14575" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Garrison-2022-TOV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Combining elements of biology, chemistry, physics, and medicine, the science of human physiology is complex and multifaceted. In this report, we offer a broad and multiscale perspective on key developments and challenges in visualization for physiology. Our literature search process combined standard methods with a state-of-the-art visual analysis search tool to identify surveys and representative individual approaches for physiology. Our resulting taxonomy sorts literature on two levels. The first level categorizes literature according to organizational complexity and ranges from molecule to organ. A second level identifies any of three high-level visualization tasks within a given work: exploration, analysis, and communication. The findings of this report may be used by visualization researchers to understand the overarching trends, challenges, and opportunities in visualization for physiology and to provide a foundation for discussion and future research directions in this area.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Kristiansen-2021-SSG.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Kristiansen-2021-SSG.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kristiansen-2022-SSG" class="col-sm-8"> <div class="title">Semantic Snapping for Guided Multi-View Visualization Design</div> <div class="author"> Yngve Sekse Kristiansen, Laura Garrison, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Jan 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2021.3114860" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Kristiansen-2021-SSG.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Visual information displays are typically composed of multiple visualizations that are used to facilitate an understanding of the underlying data. A common example are dashboards, which are frequently used in domains such as finance, process monitoring and business intelligence. However, users may not be aware of existing guidelines and lack expert design knowledge when composing such multi-view visualizations. In this paper, we present semantic snapping, an approach to help non-expert users design effective multi-view visualizations from sets of pre-existing views. When a particular view is placed on a canvas, it is “aligned” with the remaining views–not with respect to its geometric layout, but based on aspects of the visual encoding itself, such as how data dimensions are mapped to channels. Our method uses an on-the-fly procedure to detect and suggest resolutions for conflicting, misleading, or ambiguous designs, as well as to provide suggestions for alternative presentations. With this approach, users can be guided to avoid common pitfalls encountered when composing visualizations. Our provided examples and case studies demonstrate the usefulness and validity of our approach.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Garrison-2021-EPP.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Garrison-2021-EPP.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Garrison-2021-EPP" class="col-sm-8"> <div class="title">An Exploration of Practice and Preferences for the Visual Communication of Biomedical Processes</div> <div class="author"> Laura Garrison, Monique Meuschke, Jennifer Fairman, Noeska Smit, Bernhard Preim, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Proceedings of VCBM</em>, Sep 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/vcbm.20211339" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Garrison-2021-EPP.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/lauragarrison87/Biomedical_Process_Vis" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>The visual communication of biomedical processes draws from diverse techniques in both visualization and biomedical illustration. However, matching these techniques to their intended audience often relies on practice-based heuristics or narrow-scope evaluations. We present an exploratory study of the criteria that audiences use when evaluating a biomedical process visualization targeted for communication. Designed over a series of expert interviews and focus groups, our study focuses on common communication scenarios of five well-known biomedical processes and their standard visual representations. We framed these scenarios in a survey with participant expertise spanning from minimal to expert knowledge of a given topic. Our results show frequent overlap in abstraction preferences between expert and non-expert audiences, with similar prioritization of clarity and the ability of an asset to meet a given communication objective. We also found that some illustrative conventions are not as clear as we thought, e.g., glows have broadly ambiguous meaning, while other approaches were unexpectedly preferred, e.g., biomedical illustrations in place of data-driven visualizations. Our findings suggest numerous opportunities for the continued convergence of visualization and biomedical illustration techniques for targeted visualization design.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bolte-2021-SVM.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bolte-2021-SVM.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bolte-2021-SVM" class="col-sm-8"> <div class="title">SplitStreams: A Visual Metaphor for Evolving Hierarchies</div> <div class="author"> Fabian Bolte, Mahsan Nourani, Eric Ragan, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Aug 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2020.2973564" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bolte-2021-SVM.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/cadanox/SplitStreams" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>The visualization of hierarchically structured data over time is an ongoing challenge and several approaches exist trying to solve it. Techniques such as animated or juxtaposed tree visualizations are not capable of providing a good overview of the time series and lack expressiveness in conveying changes over time. Nested streamgraphs provide a better understanding of the data evolution, but lack the clear outline of hierarchical structures at a given timestep. Furthermore, these approaches are often limited to static hierarchies or exclude complex hierarchical changes in the data, limiting their use cases. We propose a novel visual metaphor capable of providing a static overview of all hierarchical changes over time, as well as clearly outlining the hierarchical structure at each individual time step. Our method allows for smooth transitions between tree maps and nested streamgraphs, enabling the exploration of the trade-off between dynamic behavior and hierarchical structure. As our technique handles topological changes of all types, it is suitable for a wide range of applications. We demonstrate the utility of our method on several use cases, evaluate it with a user study, and provide its full source code.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bolte-2021-VVE.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bolte-2021-VVE.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bolte-2021-VVE" class="col-sm-8"> <div class="title">Vis-a-Vis: Visual Exploration of Visualization Source Code Evolution</div> <div class="author"> Fabian Bolte, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Jul 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2019.2963651" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bolte-2021-VVE.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=5XO6BU4j1KQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Developing an algorithm for a visualization prototype often involves the direct comparison of different development stages and design decisions, and even minor modifications may dramatically affect the results. While existing development tools provide visualizations for gaining general insight into performance and structural aspects of the source code, they neglect the central importance of result images unique to graphical algorithms. In this paper, we present a novel approach that enables visualization programmers to simultaneously explore the evolution of their algorithm during the development phase together with its corresponding visual outcomes by providing an automatically updating meta visualization. Our interactive system allows for the direct comparison of all development states on both the visual and the source code level, by providing easy to use navigation and comparison tools. The on-the-fly construction of difference images, source code differences, and a visual representation of the source code structure further enhance the user’s insight into the states’ interconnected changes over time. Our solution is accessible via a web-based interface that provides GPU-accelerated live execution of C++ and GLSL code, as well as supporting a domain-specific programming language for scientific visualization.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Diehl-2021-HTC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Diehl-2021-HTC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Diehl-2021-HTC" class="col-sm-8"> <div class="title">Hornero: Thunderstorms Characterization using Visual Analytics</div> <div class="author"> Alexandra Diehl, Rodrigo Pelorosso, Juan Ruiz, Renato Pajarola, Meister Eduard Gröller, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Jun 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.14308" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Diehl-2021-HTC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Analyzing the evolution of thunderstorms is critical in determining the potential for the development of severe weather events. Existing visualization systems for short-term weather forecasting (nowcasting) allow for basic analysis and prediction of storm developments. However, they lack advanced visual features for efficient decision-making. We developed a visual analytics tool for the detection of hazardous thunderstorms and their characterization, using a visual design centered on a reformulated expert task workflow that includes visual features to overview storms and quickly identify high-impact weather events, a novel storm graph visualization to inspect and analyze the storm structure, as well as a set of interactive views for efficient identification of similar storm cells (known as analogs) in historical data and their use for nowcasting. Our tool was designed with and evaluated by meteorologists and expert forecasters working in short-term operational weather forecasting of severe weather events. Results show that our solution suits the forecasters’ workflow. Our visual design is expressive, easy to use, and effective for prompt analysis and quick decision-making in the context of short-range operational weather forecasting.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Garrison-2021-DIH.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Garrison-2021-DIH.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Garrison-2021-DIH" class="col-sm-8"> <div class="title">DimLift: Interactive Hierarchical Data Exploration through Dimensional Bundling</div> <div class="author"> Laura Garrison, Juliane Müller, Stefanie Schreiber, Steffen Oeltze-Jafra, Helwig Hauser, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Jun 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2021.3057519" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Garrison-2021-DIH.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/JSZuhnDyugA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/lauragarrison87/DimLift" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>The identification of interesting patterns and relationships is essential to exploratory data analysis. This becomes increasingly difficult in high dimensional datasets. While dimensionality reduction techniques can be utilized to reduce the analysis space, these may unintentionally bury key dimensions within a larger grouping and obfuscate meaningful patterns. With this work we introduce DimLift, a novel visual analysis method for creating and interacting with dimensional bundles. Generated through an iterative dimensionality reduction or user-driven approach, dimensional bundles are expressive groups of dimensions that contribute similarly to the variance of a dataset. Interactive exploration and reconstruction methods via a layered parallel coordinates plot allow users to lift interesting and subtle relationships to the surface, even in complex scenarios of missing and mixed data types. We exemplify the power of this technique in an expert case study on clinical cohort data alongside two additional case examples from nutrition and ecology.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Trautner-2021-LWI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Trautner-2021-LWI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Trautner-2021-LWI" class="col-sm-8"> <div class="title">Line Weaver: Importance-Driven Order Enhanced Rendering of Dense Line Charts</div> <div class="author"> Thomas Trautner, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Jun 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.14316" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Trautner-2021-LWI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Line charts are an effective and widely used technique for visualizing series of ordered two-dimensional data points. The relationship between consecutive points is indicated by connecting line segments, revealing potential trends or clusters in the underlying data. However, when dealing with an increasing number of lines, the render order substantially influences the resulting visualization. Rendering transparent lines can help but unfortunately the blending order is currently either ignored or naively used, for example, assuming it is implicitly given by the order in which the data was saved in a file. Due to the noncommutativity of classic alpha blending, this results in contradicting visualizations of the same underlying data set, so-called "hallucinators". In this paper, we therefore present line weaver, a novel visualization technique for dense line charts. Using an importance function, we developed an approach that correctly considers the blending order independently of the render order and without any prior sorting of the data. We allow for importance functions which are either explicitly given or implicitly derived from the geometric properties of the data if no external data is available. The importance can then be applied globally to entire lines, or locally per pixel which simultaneously supports various types of user interaction. Finally, we discuss the potential of our contribution based on different synthetic and real-world data sets where classic or naive approaches would fail.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Mueller-2021-IDA.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Mueller-2021-IDA.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Mueller-2021-IDA" class="col-sm-8"> <div class="title">Integrated Dual Analysis of Quantitative and Qualitative High-Dimensional Data</div> <div class="author"> Juliane Müller, Laura Garrison, Philipp Ulbrich, Stefanie Schreiber, <em>Stefan Bruckner</em>, Helwig Hauser, and Steffen Oeltze-Jafra </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Feb 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2021.3056424" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Mueller-2021-IDA.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/JulianeMu/IntegratedDualAnalysisAproach_MDA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>The Dual Analysis framework is a powerful enabling technology for the exploration of high dimensional quantitative data by treating data dimensions as first-class objects that can be explored in tandem with data values. In this work, we extend the Dual Analysis framework through the joint treatment of quantitative (numerical) and qualitative (categorical) dimensions. Computing common measures for all dimensions allows us to visualize both quantitative and qualitative dimensions in the same view. This enables a natural joint treatment of mixed data during interactive visual exploration and analysis. Several measures of variation for nominal qualitative data can also be applied to ordinal qualitative and quantitative data. For example, instead of measuring variability from a mean or median, other measures assess inter-data variation or average variation from a mode. In this work, we demonstrate how these measures can be integrated into the Dual Analysis framework to explore and generate hypotheses about high-dimensional mixed data. A medical case study using clinical routine data of patients suffering from Cerebral Small Vessel Disease (CSVD), conducted with a senior neurologist and a medical student, shows that a joint Dual Analysis approach for quantitative and qualitative data can rapidly lead to new insights based on which new hypotheses may be generated.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Garrison-2020-IVE.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Garrison-2020-IVE.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Garrison-2020-IVE" class="col-sm-8"> <div class="title">Interactive Visual Exploration of Metabolite Ratios in MR Spectroscopy Studies</div> <div class="author"> Laura Garrison, Jakub Vašíček, Alex R. Craven, Renate Grüner, Noeska Smit, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computers &amp; Graphics</em>, Nov 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.cag.2020.08.001" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Garrison-2020-IVE.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Magnetic resonance spectroscopy (MRS) is an advanced biochemical technique used to identify metabolic compounds in living tissue. While its sensitivity and specificity to chemical imbalances render it a valuable tool in clinical assessment, the results from this modality are abstract and difficult to interpret. With this design study we characterized and explored the tasks and requirements for evaluating these data from the perspective of a MRS research specialist. Our resulting tool, SpectraMosaic, links with upstream spectroscopy quantification software to provide a means for precise interactive visual analysis of metabolites with both single- and multi-peak spectral signatures. Using a layered visual approach, SpectraMosaic allows researchers to analyze any permutation of metabolites in ratio form for an entire cohort, or by sample region, individual, acquisition date, or brain activity status at the time of acquisition. A case study with three MRS researchers demonstrates the utility of our approach in rapid and iterative spectral data analysis.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Kristiansen-2020-VIV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Kristiansen-2020-VIV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kristiansen-2020-VIV" class="col-sm-8"> <div class="title">Visception: An Interactive Visual Framework for Nested Visualization Design</div> <div class="author"> Yngve Sekse Kristiansen, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computers &amp; Graphics</em>, Nov 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.cag.2020.08.007" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Kristiansen-2020-VIV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Nesting is the embedding of charts into the marks of another chart. Related to principles such as Tufte’s rule of utilizing micro/macro readings, nested visualizations have been employed to increase information density, providing compact representations of multi-dimensional and multi-typed data entities. Visual authoring tools are becoming increasingly prevalent, as they make visualization technology accessible to non-expert users such as data journalists, but existing frameworks provide no or only very limited functionality related to the creation of nested visualizations. In this paper, we present an interactive visual approach for the flexible generation of nested multilayer visualizations. Based on a hierarchical representation of nesting relationships coupled with a highly customizable mechanism for specifying data mappings, we contribute a flexible framework that enables defining and editing data-driven multi-level visualizations. As a demonstration of the viability of our framework, we contribute a visual builder for exploring, customizing and switching between different designs, along with example visualizations to demonstrate the range of expression. The resulting system allows for the generation of complex nested charts with a high degree of flexibility and fluidity using a drag and drop interface.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Moerth-2020-PPI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Moerth-2020-PPI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Moerth-2020-PPI" class="col-sm-8"> <div class="title">ParaGlyder: Probe-driven Interactive Visual Analysis for Multiparametric Medical Imaging Data</div> <div class="author"> Eric Mörth, Ingfrid Haldorsen, <em>Stefan Bruckner</em>, and Noeska Smit </div> <div class="periodical"> <em>In Proceedings of CGI</em>, Oct 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-030-61864-3_29" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Moerth-2020-PPI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/S_M4CWXKz0U" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Multiparametric medical imaging describes approaches that include multiple imaging sequences acquired within the same imaging examination, as opposed to one single imaging sequence or imaging from multiple imaging modalities. Multiparametric imaging in cancer has been shown to be useful for tumor detection and may also depict functional tumor characteristics relevant for clinical phenotypes. However, when confronted with datasets consisting of multiple values per voxel, traditional reading of the imaging series fails to capture complicated patterns. Those patterns of potentially important imaging properties of the parameter space may be critical for the analysis. Standard approaches, such as transfer functions and juxtapositioned visualizations, fail to convey the shape of the multiparametric parameter distribution in sufficient detail. For these reasons, in this paper we present an approach that aims to enable the exploration and analysis of such multiparametric studies using an interactive visual analysis application to remedy the trade-offs between details in the value domain and in spatial resolution. Interactive probing within or across subjects allows for a digital biopsy that is able to uncover multiparametric tissue properties. This may aid in the discrimination between healthy and cancerous tissue, unravel radiomic tissue features that could be linked to targetable pathogenic mechanisms, and potentially highlight metastases that evolved from the primary tumor. We conducted an evaluation with eleven domain experts from the field of gynecological cancer imaging, neurological imaging, and machine learning research to confirm the utility of our approach.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Moerth-2020-RIV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Moerth-2020-RIV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Moerth-2020-RIV" class="col-sm-8"> <div class="title">RadEx: Integrated Visual Exploration of Multiparametric Studies for Radiomic Tumor Profiling</div> <div class="author"> Eric Mörth, Kari Wagner-Larsen, Erlend Hodneland, Camilla Krakstad, Ingfrid Haldorsen, <em>Stefan Bruckner</em>, and Noeska Smit </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Oct 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/doi:10.1111/cgf.14172" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Moerth-2020-RIV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Better understanding of the complex processes driving tumor growth and metastases is critical for developing targeted treatment strategies in cancer. Radiomics extracts large amounts of features from medical images which enables radiomic tumor profiling in combination with clinical markers. However, analyzing complex imaging data in combination with clinical data is not trivial and supporting tools aiding in these exploratory analyses are presently missing. In this paper, we present an approach that aims to enable the analysis of multiparametric medical imaging data in combination with numerical, ordinal, and categorical clinical parameters to validate established and unravel novel biomarkers. We propose a hybrid approach where dimensionality reduction to a single axis is combined with multiple linked views allowing clinical experts to formulate hypotheses based on all available imaging data and clinical parameters. This may help to reveal novel tumor characteristics in relation to molecular targets for treatment, thus providing better tools for enabling more personalized targeted treatment strategies. To confirm the utility of our approach, we closely collaborate with experts from the field of gynecological cancer imaging and conducted an evaluation with six experts in this field.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bolte-2020-MVS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bolte-2020-MVS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bolte-2020-MVS" class="col-sm-8"> <div class="title">Measures in Visualization Space</div> <div class="author"> Fabian Bolte, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Foundations of Data Visualization</em>, Aug 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-030-34444-3_3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bolte-2020-MVS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Measurement is an integral part of modern science, providing the fundamental means for evaluation, comparison, and prediction. In the context of visualization, several different types of measures have been proposed, ranging from approaches that evaluate particular aspects of individual visualization techniques, their perceptual characteristics, and even economic factors. Furthermore, there are approaches that attempt to provide means for measuring general properties of the visualization process as a whole. Measures can be quantitative or qualitative, and one of the primary goals is to provide objective means for reasoning about visualizations and their effectiveness. As such, they play a central role in the development of scientific theories for visualization. In this chapter, we provide an overview of the current state of the art, survey and classify different types of visualization measures, characterize their strengths and drawbacks, and provide an outline of open challenges for future research.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/StormFurru-2020-VGT.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="StormFurru-2020-VGT.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="StormFurru-2020-VGT" class="col-sm-8"> <div class="title">VA-TRAC: Geospatial Trajectory Analysis for Monitoring, Identification, and Verification in Fishing Vessel Operations</div> <div class="author"> Syver Storm-Furru, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Jun 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.13966" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/StormFurru-2020-VGT.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In order to ensure sustainability, fishing operations are governed by many rules and regulations that restrict the use of certain techniques and equipment, specify the species and size of fish that can be harvested, and regulate commercial activities based on licensing schemes. As the world’s second largest exporter of fish and seafood products, Norway invests a significant amount of effort into maintaining natural ecosystem dynamics by ensuring compliance with its constantly evolving science based regulatory body. This paper introduces VA-TRAC, a geovisual analytics application developed in collaboration with the Norwegian Directorate of Fisheries in order to address this complex task. Our approach uses automatic methods to identify possible catch operations based on fishing vessel trajectories, embedded in an interactive web-based visual interface used to explore the results, compare them with licensing information, and incorporate the analysts’ domain knowledge into the decision making process. We present a data and task analysis based on a close collaboration with domain experts, and the design and implementation of VA-TRAC to address the identified requirements.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bolte-2020-ONC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bolte-2020-ONC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bolte-2020-ONC" class="col-sm-8"> <div class="title">Organic Narrative Charts</div> <div class="author"> Fabian Bolte, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Proceedings of Eurographics (Short Papers)</em>, May 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/egs.20201026" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bolte-2020-ONC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/cadanox/orcha" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Storyline visualizations display the interactions of groups and entities and their development over time. Existing approaches have successfully adopted the general layout from hand-drawn illustrations to automatically create similar depictions. Ward Shelley is the author of several diagrammatic paintings that show the timeline of art-related subjects, such as Downtown Body, a history of art scenes. His drawings include many stylistic elements that are not covered by existing storyline visualizations, like links between entities, splits and merges of streams, and tags or labels to describe the individual elements. We present a visualization method that provides a visual mapping for the complex relationships in the data, creates a layout for their display, and adopts a similar styling of elements to imitate the artistic appeal of such illustrations.We compare our results to the original drawings and provide an open-source authoring tool prototype.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Trautner-2020-SPM.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Trautner-2020-SPM.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Trautner-2020-SPM" class="col-sm-8"> <div class="title">Sunspot Plots: Model-based Structure Enhancement for Dense Scatter Plots</div> <div class="author"> Thomas Trautner, Fabian Bolte, Sergej Stoppel, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computer Graphics Forum</em>, May 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.14001" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Trautner-2020-SPM.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/G6l-y6YGjzQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Scatter plots are a powerful and well-established technique for visualizing the relationships between two variables as a collection of discrete points. However, especially when dealing with large and dense data, scatter plots often exhibit problems such as overplotting, making the data interpretation arduous. Density plots are able to overcome these limitations in highly populated regions, but fail to provide accurate information of individual data points. This is particularly problematic in sparse regions where the density estimate may not provide a good representation of the underlying data. In this paper, we present sunspot plots, a visualization technique that communicates dense data as a continuous data distribution, while preserving the discrete nature of data samples in sparsely populated areas. We furthermore demonstrate the advantages of our approach on typical failure cases of scatter plots within synthetic and real-world data sets and validate its effectiveness in a user study.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Solteszova-2019-MLT.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Solteszova-2019-MLT.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Solteszova-2019-MLT" class="col-sm-8"> <div class="title">Memento: Localized Time-Warping for Spatio-Temporal Selection</div> <div class="author"> Veronika Solteszova, Noeska Smit, Sergej Stoppel, Renate Grüner, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Feb 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.13763" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Solteszova-2019-MLT.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Abstract Interaction techniques for temporal data are often focused on affecting the spatial aspects of the data, for instance through the use of transfer functions, camera navigation or clipping planes. However, the temporal aspect of the data interaction is often neglected. The temporal component is either visualized as individual time steps, an animation or a static summary over the temporal domain. When dealing with streaming data, these techniques are unable to cope with the task of re-viewing an interesting local spatio-temporal event, while continuing to observe the rest of the feed. We propose a novel technique that allows users to interactively specify areas of interest in the spatio-temporal domain. By employing a time-warp function, we are able to slow down time, freeze time or even travel back in time, around spatio-temporal events of interest. The combination of such a (pre-defined) time-warp function and brushing directly in the data to select regions of interest allows for a detailed review of temporally and spatially localized events, while maintaining an overview of the global spatio-temporal data. We demonstrate the utility of our technique with several usage scenarios.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Palenik-2019-SSR.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Palenik-2019-SSR.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Palenik-2019-SSR" class="col-sm-8"> <div class="title">Scale-Space Splatting: Reforming Spacetime for Cross-Scale Exploration of Integral Measures in Molecular Dynamics</div> <div class="author"> Juraj Pálenik, Jan Byška, <em>Stefan Bruckner</em>, and Helwig Hauser </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Jan 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2019.2934258" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Palenik-2019-SSR.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Understanding large amounts of spatiotemporal data from particle-based simulations, such as molecular dynamics, often relies on the computation and analysis of aggregate measures. These, however, by virtue of aggregation, hide structural information about the space/time localization of the studied phenomena. This leads to degenerate cases where the measures fail to capture distinct behaviour. In order to drill into these aggregate values, we propose a multi-scale visual exploration technique. Our novel representation, based on partial domain aggregation, enables the construction of a continuous scale-space for discrete datasets and the simultaneous exploration of scales in both space and time. We link these two scale-spaces in a scale-space space-time cube and model linked views as orthogonal slices through this cube, thus enabling the rapid identification of spatio-temporal patterns at multiple scales. To demonstrate the effectiveness of our approach, we showcase an advanced exploration of a protein-ligand simulation.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bartsch-2019-MVA.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bartsch-2019-MVA.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bartsch-2019-MVA" class="col-sm-8"> <div class="title">MedUse: A Visual Analysis Tool for Medication Use Data in the ABCD Study</div> <div class="author"> Hauke Bartsch, Laura Garrison, <em>Stefan Bruckner</em>, Ariel Wang, Susan F. Tapert, and Renate Grüner </div> <div class="periodical"> <em>In Proceedings of VCBM (Short Papers)</em>, Sep 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/vcbm.20191236" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bartsch-2019-MVA.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>The RxNorm vocabulary is a yearly-published biomedical resource providing normalized names for medications. It is used to capture medication use in the Adolescent Brain Cognitive Development (ABCD) study, an active and publicly available longitudinal research study following 11,800 children over 10 years. In this work, we present medUse, a visual tool allowing researchers to explore and analyze the relationship of drug category to cognitive or imaging derived measures using ABCD study data. Our tool provides position-based context for tree traversal and selection granularity of both study participants and drug category. Developed as part of the Data Exploration and Analysis Portal (DEAP), medUse is available to more than 600 ABCD researchers world-wide. By integrating medUse into an actively used research product we are able to reach a wide audience and increase the practical relevance of visualization for the biomedical field.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Garrison-2019-SET.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Garrison-2019-SET.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Garrison-2019-SET" class="col-sm-8"> <div class="title">SpectraMosaic: An Exploratory Tool for the Interactive Visual Analysis of Magnetic Resonance Spectroscopy Data</div> <div class="author"> Laura Garrison, Jakub Vašı́ček, Renate Grüner, Noeska Smit, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Proceedings of VCBM</em>, Sep 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/0.2312/vcbm.20191225" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Garrison-2019-SET.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=Rzl7sl4WvdQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://git.app.uib.no/Laura.Garrison/spectramosaic" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Magnetic resonance spectroscopy (MRS) allows for assessment of tissue metabolite characteristics used often for early detection and treatment evaluation of brain-related pathologies. However, meaningful variations in ratios of tissue metabolites within a sample area are difficult to capture with current visualization tools. Furthermore, the learning curve to interpretation is steep and limits the more widespread adoption of MRS in clinical practice. In this design study, we collaborated with domain experts to design a novel visualization tool for the exploration of tissue metabolite concentration ratios in spectroscopy clinical and research studies. We present a data and task analysis for this domain, where MRS data attributes can be categorized into tiers of visual priority. We furthermore introduce a novel set of visual encodings for these attributes. Our result is SpectraMosaic (see Figure \reffig:teaser), an interactive insight-generation tool for rapid exploration and comparison of metabolite ratios. We validate our approach with two case studies from MR spectroscopy experts, providing early qualitative evidence of the efficacy of the system for visualization of spectral data and affording deeper insights into these complex heterogeneous data.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Stoppel-2019-LFL.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Stoppel-2019-LFL.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Stoppel-2019-LFL" class="col-sm-8"> <div class="title">LinesLab: A Flexible Low-Cost Approach for the Generation of Physical Monochrome Art</div> <div class="author"> Sergej Stoppel, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Sep 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.13609" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Stoppel-2019-LFL.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=WdZJmU6fOAY" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>The desire for the physical generation of computer art has seen a significant body of research that has resulted in sophisticated robots and painting machines, together with specialized algorithms mimicking particular artistic techniques. The resulting setups are often expensive and complex, making them unavailable for recreational and hobbyist use. In recent years, however, a new class of affordable low-cost plotters and cutting machines has reached the market. In this paper, we present a novel system for the physical generation of line and cut-out art based on digital images, targeted at such off-the-shelf devices. Our approach uses a meta-optimization process to generate results that represent the tonal content of a digital image while conforming to the physical and mechanical constraints of home-use devices. By flexibly combining basic sets of positional and shape encodings, we are able to recreate a wide range of artistic styles. Furthermore, our system optimizes the output in terms of visual perception based on the desired viewing distance, while remaining scalable with respect to the medium size.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2018-MSD.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2018-MSD.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2018-MSD" class="col-sm-8"> <div class="title">A Model of Spatial Directness in Interactive Visualization</div> <div class="author"> <em>Stefan Bruckner</em>, Tobias Isenberg, Timo Ropinski, and Alexander Wiebel </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Aug 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2018.2848906" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2018-MSD.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We discuss the concept of directness in the context of spatial interaction with visualization. In particular, we propose a model that allows practitioners to analyze and describe the spatial directness of interaction techniques, ultimately to be able to better understandinteraction issues that may affect usability. To reach these goals, we distinguish between different types of directness. Each type of directness depends on a particular mapping between different spaces, for which we consider the data space, the visualization space, the output space, the user space, the manipulation space, and the interaction space. In addition to the introduction of the model itself, we alsoshow how to apply it to several real-world interaction scenarios in visualization, and thus discuss the resulting types of spatial directness,without recommending either more direct or more indirect interaction techniques. In particular, we will demonstrate descriptive and evaluative usage of the proposed model, and also briefly discuss its generative usage.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Smit-2019-TAV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Smit-2019-TAV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Smit-2019-TAV" class="col-sm-8"> <div class="title">Towards Advanced Interactive Visualization for Virtual Atlases</div> <div class="author"> Noeska Smit, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Biomedical Visualisation</em>, Jul 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-030-19385-0_6" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Smit-2019-TAV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>An atlas is generally defined as a bound collection of tables, charts or illustrations describing a phenomenon. In an anatomical atlas for example, a collection of representative illustrations and text describes anatomy for the purpose of communicating anatomical knowledge. The atlas serves as reference frame for comparing and integrating data from different sources by spatially or semantically relating collections of drawings, imaging data, and/or text. In the field of medical image processing, atlas information is often constructed from a collection of regions of interest, which are based on medical images that are annotated by domain experts. Such an atlas may be employed for example for automatic segmentation of medical imaging data. The combination of interactive visualization techniques with atlas information opens up new possibilities for content creation, curation, and navigation in virtual atlases. With interactive visualization of atlas information, students are able to inspect and explore anatomical atlases in ways that were not possible with the traditional method of presenting anatomical atlases in book format, such as viewing the illustrations from other viewpoints. With advanced interaction techniques, it becomes possible to query the data that forms the basis for the atlas, thus empowering researchers to access a wealth of information in new ways. So far, atlas based visualization has been employed for mainly medical education, as well as biological research. In this survey, we provide an overview of current digital biomedical atlas tasks and applications and summarize relevant visualization techniques. We discuss recent approaches for providing next-generation visual interfaces to navigate atlas data that go beyond common text-based search and hierarchical lists. Finally, we reflect on open challenges and opportunities for the next steps in interactive atlas visualization.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Garrison-2019-VES.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Garrison-2019-VES.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Garrison-2019-VES" class="col-sm-8"> <div class="title">A Visual Encoding System for Comparative Exploration of Magnetic Resonance Spectroscopy Data</div> <div class="author"> Laura Garrison, Jakub Vašı́ček, Renate Grüner, Noeska Smit, and <em>Stefan Bruckner</em> </div> <div class="periodical"> Jun 2019 </div> <div class="periodical"> Best Poster Award at EuroVis 2019 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Garrison-2019-VES.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/Rzl7sl4WvdQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Magnetic resonance spectroscopy (MRS) allows for assessment of tissue metabolite characteristics used often for early detection and treatment evaluation of intracranial pathologies. In particular, this non-invasive technique is important in the study of metabolic changes related to brain tumors, strokes, seizure disorders, Alzheimer’s disease, depression, as well as other diseases and disorders affecting the brain. However, meaningful variations in ratios of tissue metabolites within a sample area are difficult to capture with current visualization tools. Furthermore, the learning curve to interpretation is steep and limits the more widespread adoption of MRS in clinical practice. In this work we present a novel, tiered visual encoding system for multi-dimensional MRS data to aid in the visual exploration of metabolite concentration ratios. Our system was developed in close collaboration with domain experts including detailed data and task analyses. This visual encoding system was subsequently realized as part of an interactive insight-generation tool for rapid exploration and comparison of metabolite ratio variation for deeper insights to these complex data.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2019-DVM.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2019-DVM.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2019-DVM" class="col-sm-8"> <div class="title">Dynamic Visibility-Driven Molecular Surfaces</div> <div class="author"> <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computer Graphics Forum</em>, May 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.13640" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2019-DVM.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=aZmDhTbJlAM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/sbruckner/dynamol.git" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Molecular surface representations are an important tool for the visual analysis of molecular structure and function. In this paper, we present a novel method for the visualization of dynamic molecular surfaces based on the Gaussian model. In contrast to previous approaches, our technique does not rely on the construction of intermediate representations such as grids or triangulated surfaces. Instead, it operates entirely in image space, which enables us to exploit visibility information to efficiently skip unnecessary computations. With this visibility-driven approach, we can visualize dynamic high-quality surfaces for molecules consisting of millions of atoms. Our approach requires no preprocessing, allows for the interactive adjustment of all properties and parameters, and is significantly faster than previous approaches, while providing superior quality.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Smit-2019-MVM.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Smit-2019-MVM.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Smit-2019-MVM" class="col-sm-8"> <div class="title">Model-based Visualization for Medical Education and Training</div> <div class="author"> Noeska Smit, Kai Lawonn, Annelot Kraima, Marco deRuiter, <em>Stefan Bruckner</em>, Elmar Eisemann, and Anna Vilanova </div> <div class="periodical"> <em>In Proceedings of Eurographics (Dirk Bartz Prize)</em>, May 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/egm.20191033" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Smit-2019-MVM.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Anatomy, or the study of the structure of the human body, is an essential component of medical education. Certain parts of human anatomy are considered to be more complex to understand than others, due to a multitude of closely related structures. Furthermore, there are many potential variations in anatomy, e.g., different topologies of vessels, and knowledge of these variations is critical for many in medical practice. Some aspects of individual anatomy, such as the autonomic nerves, are not visible in individuals through medical imaging techniques or even during surgery, placing these nerves at risk for damage. 3D models and interactive visualization techniques can be used to improve understanding of this complex anatomy, in combination with traditional medical education paradigms. We present a framework incorporating several advanced medical visualization techniques and applications for teaching and training purposes, which is the result of an interdisciplinary project. In contrast to previous approaches which focus on general anatomy visualization or direct visualization of medical imaging data, we employ model-based techniques to represent variational anatomy, as well as anatomy not visible from imaging. Our framework covers the complete spectrum including general anatomy, anatomical variations, and anatomy in individual patients. Applications within our framework were evaluated positively with medical users, and our educational tool for general anatomy is in use in a Massive Open Online Course (MOOC) on anatomy, which had over 17000 participants worldwide in the first run.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Stoppel-2019-FVI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Stoppel-2019-FVI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Stoppel-2019-FVI" class="col-sm-8"> <div class="title">Firefly: Virtual Illumination Drones for Interactive Visualization</div> <div class="author"> Sergej Stoppel, Magnus Paulson Erga, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Jan 2019 </div> <div class="periodical"> Best SciVis Paper Honorable Mention at VIS 2018 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2018.2864656" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Stoppel-2019-FVI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Light specification in three dimensional scenes is a complex problem and several approaches have been presented that aim to automate this process. However, there are many scenarios where a static light setup is insufficient, as the scene content and camera position may change. Simultaneous manual control over the camera and light position imposes a high cognitive load on the user. To address this challenge, we introduce a novel approach for automatic scene illumination with Fireflies. Fireflies are intelligent virtual light drones that illuminate the scene by traveling on a closed path. The Firefly path automatically adapts to changes in the scene based on an outcome-oriented energy function. To achieve interactive performance, we employ a parallel rendering pipeline for the light path evaluations. We provide a catalog of energy functions for various application scenarios and discuss the applicability of our method on several examples.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Stoppel-2018-SSW.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Stoppel-2018-SSW.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Stoppel-2018-SSW" class="col-sm-8"> <div class="title">Smart Surrogate Widgets for Direct Volume Manipulation</div> <div class="author"> Sergej Stoppel, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Proceedings of IEEE PacificVis</em>, Apr 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/PacificVis.2018.00014" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Stoppel-2018-SSW.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=wMRw-W0SrLk" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Interaction is an essential aspect in volume visualization, yet common manipulation tools such as bounding boxes or clipping plane widgets provide rather crude tools as they neglect the complex structure of the underlying data. In this paper, we introduce a novel volume interaction approach based on smart widgets that are automatically placed directly into the data in a visibility-driven manner.By adapting to what the user actually sees, they act as proxies that allow for goal-oriented modifications while still providing an intuitive set of simple operations that is easy to control. In particular, our method is well-suited for direct manipulation scenarios such as touchscreens, where traditional user interface elements commonly exhibit limited utility. To evaluate out approach we conducted a qualitative user study with nine participants with various backgrounds.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Magnus-2018-IDV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Magnus-2018-IDV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Magnus-2018-VPI" class="col-sm-8"> <div class="title">Interactive Dynamic Volume Illumination with Refraction and Caustics</div> <div class="author"> Jens G. Magnus, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Phoenix, USA, Jan 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2017.2744438" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Magnus-2018-IDV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=3tn6sSXw4NQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In recent years, significant progress has been made in developing high-quality interactive methods for realistic volume illumination. However, refraction – despite being an important aspect of light propagation in participating media – has so far only received little attention. In this paper, we present a novel approach for refractive volume illumination including caustics capable of interactive frame rates. By interleaving light and viewing ray propagation, our technique avoids memory-intensive storage of illumination information and does not require any precomputation. It is fully dynamic and all parameters such as light position and transfer function can be modified interactively without a performance penalty.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Diehl-2017-AVA.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Diehl-2017-AVA.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Diehl-2017-AVA" class="col-sm-8"> <div class="title">Albero: A Visual Analytics Approach for Probabilistic Weather Forecasting</div> <div class="author"> Alexandra Diehl, Leandro Pelorosso, Kresimir Matkovic, Juan Ruiz, Meister Eduard Gröller, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Oct 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.13279" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Diehl-2017-AVA.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=-yqoeEgkz28" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Probabilistic weather forecasts are amongst the most popular ways to quantify numerical forecast uncertainties. The analog regression method can quantify uncertainties and express them as probabilities. The method comprises the analysis of errors from a large database of past forecasts generated with a specific numerical model and observational data. Current visualization tools based on this method are essentially automated and provide limited analysis capabilities. In this paper, we propose a novel approach that breaks down the automatic process using the experience and knowledge of the users and creates a new interactive visual workflow. Our approach allows forecasters to study probabilistic forecasts, their inner analogs and observations, their associated spatial errors, and additional statistical information by means of coordinated and linked views. We designed the presented solution following a participatory methodology together with domain experts. Several meteorologists with different backgrounds validated the approach. Two case studies illustrate the capabilities of our solution. It successfully facilitates the analysis of uncertainty and systematic model biases for improved decision-making and process-quality measurements.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Mindek-2017-DVN.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Mindek-2017-DVN.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Mindek-2017-DVN" class="col-sm-8"> <div class="title">Data-Sensitive Visual Navigation</div> <div class="author"> Peter Mindek, Gabriel Mistelbauer, Meister Eduard Gröller, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computers &amp; Graphics</em>, Mikulov, Czech Republic, Oct 2017 </div> <div class="periodical"> Best Paper Award at SCCG 2017 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.cag.2017.05.012" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Mindek-2017-DVN.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=FnhbjX7BRXI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In visualization systems it is often the case that the changes of the input parameters are not proportional to the visual change of the generated output. In this paper, we propose a model for enabling data-sensitive navigation for user-interface elements. This model is applied to normalize the user input according to the visual change, and also to visually communicate this normalization. In this way, the exploration of heterogeneous data using common interaction elements can be performed in an efficient way. We apply our model to the field of medical visualization and present guided navigation tools for traversing vascular structures and for camera rotation around 3Dvolumes. The presented examples demonstrate that the model scales to user-interface elements where multiple parameters are set simultaneously.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Kolesar-2017-FCC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Kolesar-2017-FCC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kolesar-2017-FCC" class="col-sm-8"> <div class="title">A Fractional Cartesian Composition Model for Semi-spatial Comparative Visualization Design</div> <div class="author"> Ivan Kolesar, <em>Stefan Bruckner</em>, Ivan Viola, and Helwig Hauser </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Baltimore, USA, Jan 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2016.2598870" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Kolesar-2017-FCC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=_zk67fmryok" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>The study of spatial data ensembles leads to substantial visualization challenges in a variety of applications. In this paper, we present a model for comparative visualization that supports the design of according ensemble visualization solutions by partial automation. We focus on applications, where the user is interested in preserving selected spatial data characteristics of the data as much as possible—even when many ensemble members should be jointly studied using comparative visualization. In our model, we separate the design challenge into a minimal set of user-specified parameters and an optimization component for the automatic configuration of the remaining design variables. We provide an illustrated formal description of our model and exemplify our approach in the context of several application examples from different domains in order to demonstrate its generality within the class of comparative visualization problems for spatial data ensembles.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Lind-2017-CCR.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Lind-2017-CCR.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Lind-2017-CCR" class="col-sm-8"> <div class="title">Comparing Cross-Sections and 3D Renderings for Surface Matching Tasks using Physical Ground Truths</div> <div class="author"> Andreas Johnsen Lind, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Baltimore, USA, Jan 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2016.2598602" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Lind-2017-CCR.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Within the visualization community there are some well-known techniques for visualizing 3D spatial data and some general assumptions about how perception affects the performance of these techniques in practice. However, there is a lack of empirical research backing up the possible performance differences among the basic techniques for general tasks. One such assumption is that 3D renderings are better for obtaining an overview, whereas cross sectional visualizations such as the commonly used Multi- Planar Reformation (MPR) are better for supporting detailed analysis tasks. In the present study we investigated this common assumption by examining the difference in performance between MPR and 3D rendering for correctly identifying a known surface. We also examined whether prior experience working with image data affects the participant’s performance, and whether there was any difference between interactive or static versions of the visualizations. Answering this question is important because it can be used as part of a scientific and empirical basis for determining when to use which of the two techniques. An advantage of the present study compared to other studies is that several factors were taken into account to compare the two techniques. The problem was examined through an experiment with 45 participants, where physical objects were used as the known surface (ground truth). Our findings showed that: 1. The 3D renderings largely outperformed the cross sections; 2. Interactive visualizations were partially more effective than static visualizations; and 3. The high experience group did not generally outperform the low experience group.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Smit-2017-PAS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Smit-2017-PAS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Smit-2017-PAS" class="col-sm-8"> <div class="title">PelVis: Atlas-based Surgical Planning for Oncological Pelvic Surgery</div> <div class="author"> Noeska Smit, Kai Lawonn, Annelot Kraima, Marco DeRuiter, Hessam Sokooti, <em>Stefan Bruckner</em>, Elmar Eisemann, and Anna Vilanova </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Baltimore, USA, Jan 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2016.2598826" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Smit-2017-PAS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=vHp05I5-hp8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Due to the intricate relationship between the pelvic organs and vital structures, such as vessels and nerves, pelvic anatomy is often considered to be complex to comprehend. In oncological pelvic surgery, a trade-off has to be made between complete tumor resection and preserving function by preventing damage to the nerves. Damage to the autonomic nerves causes undesirable post-operative side-effects such as fecal and urinal incontinence, as well as sexual dysfunction in up to 80 percent of the cases. Since these autonomic nerves are not visible in pre-operative MRI scans or during surgery, avoiding nerve damage during such a surgical procedure becomes challenging. In this work, we present visualization methods to represent context, target, and risk structures for surgical planning. We employ distance-based and occlusion management techniques in an atlas-based surgical planning tool for oncological pelvic surgery. Patient-specific pre-operative MRI scans are registered to an atlas model that includes nerve information. Through several interactive linked views, the spatial relationships and distances between the organs, tumor and risk zones are visualized to improve understanding, while avoiding occlusion. In this way, the surgeon can examine surgically relevant structures and plan the procedure before going into the operating theater, thus raising awareness of the autonomic nerve zone regions and potentially reducing post-operative complications. Furthermore, we present the results of a domain expert evaluation with surgical oncologists that demonstrates the advantages of our approach.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Solteszova-2017-OFS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Solteszova-2017-OFS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Solteszova-2017-OFS" class="col-sm-8"> <div class="title">Output-Sensitive Filtering of Streaming Volume Data</div> <div class="author"> Veronika Šoltészová, Åsmund Birkeland, Sergej Stoppel, Ivan Viola, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Jan 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.12799" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Solteszova-2017-OFS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=xGPs560ttp0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Real-time volume data acquisition poses substantial challenges for the traditional visualization pipeline where data enhancement is typically seen as a pre-processing step. In the case of 4D ultrasound data, for instance, costly processing operations to reduce noise and to remove artifacts need to be executed for every frame. To enable the use of high quality filtering operations in such scenarios, we propose an output-sensitive approach to the visualization of streaming volume data. Our method evaluates the potential contribution of all voxels to the final image, allowing us to skip expensive processing operations that have little or no effect on the visualization. As filtering operations modify the data values which may affect the visibility, our main contribution is a fast scheme to predict their maximum effect on the final image. Our approach prioritizes filtering of voxels with high contribution to the final visualization based on a maximal permissible error per pixel. With zero permissible error, the optimized filtering will yield a result identical to filtering of the entire volume. We provide a thorough technical evaluation of the approach and demonstrate it on several typical scenarios that require on-the-fly processing.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Stoppel-2017-VPI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Stoppel-2017-VPI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Stoppel-2017-VPI" class="col-sm-8"> <div class="title">Vol<sup>2</sup>velle: Printable Interactive Volume Visualization</div> <div class="author"> Sergej Stoppel, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Baltimore, USA, Jan 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2016.2599211" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Stoppel-2017-VPI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=Z1K8t-FCiXI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Interaction is an indispensable aspect of data visualization. The presentation of volumetric data, in particular, often significantly benefits from interactive manipulation of parameters such as transfer functions, rendering styles, or clipping planes. However, when we want to create hardcopies of such visualizations, this essential aspect is lost. In this paper, we present a novel approach for creating hardcopies of volume visualizations which preserves a certain degree of interactivity. We present a method for automatically generating Volvelles, printable tangible wheel charts that can be manipulated to explore different parameter settings. Our interactive system allows the flexible mapping of arbitrary visualization parameters and supports advanced features such as linked views. The resulting designs can be easily reproduced using a standard printer and assembled within a few minutes.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Swoboda-2017-VQI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Swoboda-2017-VQI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Swoboda-2017-VQI" class="col-sm-8"> <div class="title">Visualization and Quantification for Interactive Analysis of Neural Connectivity in Drosophila</div> <div class="author"> Nicolas Swoboda, Judith Moosburner, <em>Stefan Bruckner</em>, Jai Y. Yu, Barry J. Dickson, and Katja Bühler </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Jan 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.12792" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Swoboda-2017-VQI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=bycWGQQpqks" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Neurobiologists investigate the brain of the common fruit fly Drosophila melanogaster to discover neural circuits and link them to complex behavior. Formulating new hypotheses about connectivity requires potential connectivity information between individual neurons, indicated by overlaps of arborizations of two or more neurons. As the number of higher order overlaps (i.e., overlaps of three or more arborizations) increases exponentially with the number of neurons under investigation, visualization is impeded by clutter and quantification becomes a burden. Existing solutions are restricted to visual or quantitative analysis of pairwise overlaps, as they rely on precomputed overlap data. We present a novel tool that complements existing methods for potential connectivity exploration by providing for the first time the possibility to compute and visualize higher order arborization overlaps on the fly and to interactively explore this information in both its spatial anatomical context and on a quantitative level. Qualitative evaluation by neuroscientists and non-experts demonstrated the utility and usability of the tool</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Stoppel-2016-GIR.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Stoppel-2016-GIR.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Stoppel-2016-GIR" class="col-sm-8"> <div class="title">Graxels: Information Rich Primitives for the Visualization of Time-Dependent Spatial Data</div> <div class="author"> Sergej Stoppel, Erlend Hodneland, Helwig Hauser, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Proceedings of VCBM</em>, Bergen, Norway, Sep 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/vcbm.20161286" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Stoppel-2016-GIR.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=UsClj3ytd0Y" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Time-dependent volumetric data has important applications in areas as diverse as medicine, climatology, and engineering. However, the simultaneous quantitative assessment of spatial and temporal features is very challenging. Common visualization techniques show either the whole volume in one time step (for example using direct volume rendering) or let the user select a region of interest (ROI) for which a collection of time-intensity curves is shown. In this paper, we propose a novel approach that dynamically embeds quantitative detail views in a spatial layout. Inspired by the concept of small multiples, we introduce a new primitive graxel (graph pixel). Graxels are view dependent primitives of time-intensity graphs, generated on-the-fly by aggregating per-ray information over time and image regions. Our method enables the detailed feature-aligned visual analysis of time-dependent volume data and allows interactive refinement and filtering. Temporal behaviors like frequency relations, aperiodic or periodic oscillations and their spatial context are easily perceived with our method. We demonstrate the power of our approach using examples from medicine and the natural sciences.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Klein-2016-TIV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Klein-2016-TIV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Klein-2016-TIV" class="col-sm-8"> <div class="title">Towards Interactive Visual Exploration of Parallel Programs using a Domain-Specific Language</div> <div class="author"> Tobias Klein, <em>Stefan Bruckner</em>, Meister Eduard Gröller, Markus Hadwiger, and Peter Rautek </div> <div class="periodical"> <em>In Proceedings of the International Workshop on OpenCL</em>, Vienna, Austria, Apr 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/2909437.2909459" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Klein-2016-TIV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>The use of GPUs and the massively parallel computing paradigm have become wide-spread. We describe a framework for the interactive visualization and visual analysis of the run-time behavior of massively parallel programs, especially OpenCL kernels. This facilitates understanding a program’s function and structure, finding the causes of possible slowdowns, locating program bugs, and interactively exploring and visually comparing different code variants in order to improve performance and correctness. Our approach enables very specific, user-centered analysis, both in terms of the recording of the run-time behavior and the visualization itself. Instead of having to manually write instrumented code to record data, simple code annotations tell the source-to-source compiler which code instrumentation to generate automatically. The visualization part of our framework then enables the interactive analysis of kernel run-time behavior in a way that can be very specific to a particular problem or optimization goal, such as analyzing the causes of memory bank conflicts or understanding an entire parallel algorithm.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Labschuetz-2016-JJC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Labschuetz-2016-JJC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Labschuetz-2016-JJC" class="col-sm-8"> <div class="title">JiTTree: A Just-in-Time Compiled Sparse GPU Volume Data Structure</div> <div class="author"> Matthias Labschütz, <em>Stefan Bruckner</em>, Meister Eduard Gröller, Markus Hadwiger, and Peter Rautek </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Chicago, USA, Jan 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2015.2467331" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Labschuetz-2016-JJC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Abstract—Sparse volume data structures enable the efficient representation of large but sparse volumes in GPU memory for com putation and visualization. However, the choice of a specific data structure for a given data set depends on several factors, such as the memory budget, the sparsity of the data, and data access patterns. In general, there is no single optimal sparse data structure, but a set of several candidates with individual strengths and drawbacks. One solution to this problem are hybrid data structures which locally adapt themselves to the sparsity. However, they typically suffer from increased traversal overhead which limits their utility in many applications. This paper presents JiTTree, a novel sparse hybrid volume data structure that uses just-in-time compilation to overcome these problems. By combining multiple sparse data structures and reducing traversal overhead we leverage their individual advantages. We demonstrate that hybrid data structures adapt well to a large range of data sets. They are especially superior to other sparse data structures for data sets that locally vary in sparsity. Possible optimization criteria are memory, performance and a combination thereof. Through just-in-time (JIT) compilation, JiTTree reduces the traversal overhead of the resulting optimal data structure. As a result, our hybrid volume data structure enables efficient computations on the GPU, while being superior in terms of memory usage when compared to non-hybrid data structures.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Angelelli-2015-PQA.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Angelelli-2015-PQA.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Angelelli-2015-PQA" class="col-sm-8"> <div class="title">Performance and Quality Analysis of Convolution-Based Volume Illumination</div> <div class="author"> Paolo Angelelli, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Journal of WSCG</em>, Jun 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Angelelli-2015-PQA.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Convolution-based techniques for volume rendering are among the fastest in the on-the-fly volumetric illumination category. Such methods, however, are still considerably slower than conventional local illumination techniques. In this paper we describe how to adapt two commonly used strategies for reducing aliasing artifacts, namely pre-integration and supersampling, to such techniques. These strategies can help reduce the sampling rate of the lighting information (thus the number of convolutions), bringing considerable performance benefits. We present a comparative analysis of their effectiveness in offering performance improvements. We also analyze the (negligible) differences they introduce when comparing their output to the reference method. These strategies can be highly beneficial in setups where direct volume rendering of continuously streaming data is desired and continuous recomputation of full lighting information is too expensive, or where memory constraints make it preferable not to keep additional precomputed volumetric data in memory. In such situations these strategies make single pass, convolution-based volumetric illumination models viable for a broader range of applications, and this paper provides practical guidelines for using and tuning such strategies to specific use cases.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Diehl-2015-VAS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Diehl-2015-VAS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Diehl-2015-VAS" class="col-sm-8"> <div class="title">Visual Analysis of Spatio-Temporal Data: Applications in Weather Forecasting</div> <div class="author"> Alexandra Diehl, Leandro Pelorosso, Claudio Delrieux, Celeste Saulo, Juan Ruiz, Meister Eduard Gröller, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Cagliari, Italy, May 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.12650" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Diehl-2015-VAS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=hhQwsuXpHo8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Weather conditions affect multiple aspects of human life such as economy, safety, security, and social activities. For this reason, weather forecast plays a major role in society. Currently weather forecasts are based on Numerical Weather Prediction (NWP) models that generate a representation of the atmospheric flow. Interactive visualization of geo-spatial data has been widely used in order to facilitate the analysis of NWP models. This paper presents a visualization system for the analysis of spatio-temporal patterns in short-term weather forecasts. For this purpose, we provide an interactive visualization interface that guides users from simple visual overviews to more advanced visualization techniques. Our solution presents multiple views that include a timeline with geo-referenced maps, an integrated webmap view, a forecast operation tool, a curve-pattern selector, spatial filters, and a linked meteogram. Two key contributions of this work are the timeline with geo-referenced maps and the curve-pattern selector. The latter provides novel functionality that allows users to specify and search for meaningful patterns in the data. The visual interface of our solution allows users to detect both possible weather trends and errors in the weather forecast model.We illustrate the usage of our solution with a series of case studies that were designed and validated in collaboration with domain experts.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Karimov-2015-GVE.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Karimov-2015-GVE.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Karimov-2015-GVE" class="col-sm-8"> <div class="title">Guided Volume Editing based on Histogram Dissimilarity</div> <div class="author"> Alexey Karimov, Gabriel Mistelbauer, Thomas Auzinger, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Cagliari, Italy, May 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.12621" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Karimov-2015-GVE.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=zjTYkXTm_dM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Segmentation of volumetric data is an important part of many analysis pipelines, but frequently requires manual inspection and correction. While plenty of volume editing techniques exist, it remains cumbersome and error-prone for the user to find and select appropriate regions for editing. We propose an approach to improve volume editing by detecting potential segmentation defects while considering the underlying structure of the object of interest. Our method is based on a novel histogram dissimilarity measure between individual regions, derived from structural information extracted from the initial segmentation. Based on this information, our interactive system guides the user towards potential defects, provides integrated tools for their inspection, and automatically generates suggestions for their resolution. We demonstrate that our approach can reduce interaction effort and supports the user in a comprehensive investigation for high-quality segmentations.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Mindek-2015-ASM.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Mindek-2015-ASM.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Mindek-2015-ASM" class="col-sm-8"> <div class="title">Automatized Summarization of Multiplayer Games</div> <div class="author"> Peter Mindek, Ladislav Čmolík, Ivan Viola, Meister Eduard Gröller, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Proceedings of SCCG</em>, Smolenice, Slovakia, Apr 2015 </div> <div class="periodical"> Best Paper Award at SCCG 2015 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/2788539.2788549" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Mindek-2015-ASM.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We present a novel method for creating automatized gameplay dramatization of multiplayer video games. The dramatization serves as a visual form of guidance through dynamic 3D scenes with multiple foci, typical for such games. Our goal is to convey interesting aspects of the gameplay by animated sequences creating a summary of events which occurred during the game. Our technique is based on processing many cameras, which we refer to as a flock of cameras, and events captured during the gameplay, which we organize into a so-called event graph. Each camera has a lifespan with a certain time interval and its parameters such as position or look-up vector are changing over time. Additionally, during its lifespan each camera is assigned an importance function, which is dependent on the significance of the structures that are being captured by the camera. The images captured by the cameras are composed into a single continuous video using a set of operators based on cinematographic effects. The sequence of operators is selected by traversing the event graph and looking for specific patterns corresponding to the respective operators. In this way, a large number of cameras can be processed to generate an informative visual story presenting the gameplay. Our compositing approach supports insets of camera views to account for several important cameras simultaneously. Additionally, we create seamless transitions between individual selected camera views in order to preserve temporal continuity, which helps the user to follow the virtual story of the gameplay.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Mindek-2014-MSS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Mindek-2014-MSS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Mindek-2014-MSS" class="col-sm-8"> <div class="title">Managing Spatial Selections with Contextual Snapshots</div> <div class="author"> Peter Mindek, Meister Eduard Gröller, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Dec 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.12406" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Mindek-2014-MSS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=rxEf-Okp8Xo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Spatial selections are a ubiquitous concept in visualization. By localizing particular features, they can be analysed and compared in different views. However, the semantics of such selections often depend on specific parameter settings and it can be difficult to reconstruct them without additional information. In this paper, we present the concept of contextual snapshots as an effective means for managing spatial selections in visualized data. The selections are automatically associated with the context in which they have been created. Contextual snapshots can also be used as the basis for interactive integrated and linked views, which enable in-place investigation and comparison of multiple visual representations of data. Our approach is implemented as a flexible toolkit with well-defined interfaces for integration into existing systems. We demonstrate the power and generality of our techniques by applying them to several distinct scenarios such as the visualization of simulation data, the analysis of historical documents and the display of anatomical data.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Rautek-2014-VSI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Rautek-2014-VSI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Rautek-2014-VSI" class="col-sm-8"> <div class="title">ViSlang: A System for Interpreted Domain-Specific Languages for Scientific Visualization</div> <div class="author"> Peter Rautek, <em>Stefan Bruckner</em>, Meister Eduard Gröller, and Markus Hadwiger </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Paris, France, Dec 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2014.2346318" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Rautek-2014-VSI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=DbWazwyMRNw" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Researchers from many domains use scientific visualization in their daily practice. Existing implementations of algorithms usually come with a graphical user interface (high-level interface), or as software library or source code (low-level interface). In this paper we present a system that integrates domain-specific languages (DSLs) and facilitates the creation of new DSLs. DSLs provide an effective interface for domain scientists avoiding the difficulties involved with low-level interfaces and at the same time offering more flexibility than high-level interfaces. We describe the design and implementation of ViSlang, an interpreted language specifically tailored for scientific visualization. A major contribution of our design is the extensibility of the ViSlang language. Novel DSLs that are tailored to the problems of the domain can be created and integrated into ViSlang. We show that our approach can be added to existing user interfaces to increase the flexibility for expert users on demand, but at the same time does not interfere with the user experience of novice users. To demonstrate the flexibility of our approach we present new DSLs for volume processing, querying and visualization. We report the implementation effort for new DSLs and compare our approach with Matlab and Python implementations in terms of run-time performance.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Sedlmair-2014-VPS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Sedlmair-2014-VPS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Sedlmair-2014-VPS" class="col-sm-8"> <div class="title">Visual Parameter Space Analysis: A Conceptual Framework</div> <div class="author"> Michael Sedlmair, Christoph Heinzl, <em>Stefan Bruckner</em>, Harald Piringer, and Torsten Möller </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Paris, France, Dec 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2014.2346321" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Sedlmair-2014-VPS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Schmidt-2014-YMC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Schmidt-2014-YMC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Schmidt-2014-YMC" class="col-sm-8"> <div class="title">YMCA - Your Mesh Comparison Application</div> <div class="author"> Johanna Schmidt, Reinhold Preiner, Thomas Auzinger, Michael Wimmer, Meister Eduard Gröller, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Proceedings of IEEE VAST</em>, Paris, France, Nov 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/VAST.2014.7042491" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Schmidt-2014-YMC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=1s-AmFCQRzM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Polygonal meshes can be created in several different ways. In this paper we focus on the reconstruction of meshes from point clouds, which are sets of points in 3D. Several algorithms that tackle this task already exist, but they have different benefits and drawbacks, which leads to a large number of possible reconstruction results (i.e., meshes). The evaluation of those techniques requires extensive comparisons between different meshes which is up to now done by either placing images of rendered meshes side-by-side, or by encoding differences by heat maps. A major drawback of both approaches is that they do not scale well with the number of meshes. This paper introduces a new comparative visual analysis technique for 3D meshes which enables the simultaneous comparison of several meshes and allows for the interactive exploration of their differences. Our approach gives an overview of the differences of the input meshes in a 2D view. By selecting certain areas of interest, the user can switch to a 3D representation and explore the spatial differences in detail. To inspect local variations, we provide a magic lens tool in 3D. The location and size of the lens provide further information on the variations of the reconstructions in the selected area. With our comparative visualization approach, differences between several mesh reconstruction algorithms can be easily localized and inspected.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Kolesar-2014-IIP.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Kolesar-2014-IIP.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kolesar-2014-IIP" class="col-sm-8"> <div class="title">Interactively Illustrating Polymerization using Three-level Model Fusion</div> <div class="author"> Ivan Kolesar, Julius Parulek, Ivan Viola, <em>Stefan Bruckner</em>, Anne-Kristin Stavrum, and Helwig Hauser </div> <div class="periodical"> <em>BMC Bioinformatics</em>, Oct 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1186/1471-2105-15-345" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Kolesar-2014-IIP.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=iMl5nDicmhg" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Research in cell biology is steadily contributing new knowledge about many aspects of physiological processes, both with respect to the involved molecular structures as well as their related function. Illustrations of the spatio-temporal development of such processes are not only used in biomedical education, but also can serve scientists as an additional platform for in-silico experiments. Results In this paper, we contribute a new, three-level modeling approach to illustrate physiological processes from the class of polymerization at different time scales. We integrate physical and empirical modeling, according to which approach best suits the different involved levels of detail, and we additionally enable a form of interactive steering, while the process is illustrated. We demonstrate the suitability of our approach in the context of several polymerization processes and report from a first evaluation with domain experts. Conclusion We conclude that our approach provides a new, hybrid modeling approach for illustrating the process of emergence in physiology, embedded in a densely filled environment. Our approach of a complementary fusion of three systems combines the strong points from the different modeling approaches and is capable to bridge different spatial and temporal scales.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Waldner-2014-GHI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Waldner-2014-GHI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Waldner-2014-GHI" class="col-sm-8"> <div class="title">Graphical Histories of Information Foraging</div> <div class="author"> Manuela Waldner, <em>Stefan Bruckner</em>, and Ivan Viola </div> <div class="periodical"> <em>In Proceedings of NordiCHI</em>, Oct 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/2639189.2641202" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Waldner-2014-GHI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>During information foraging, knowledge workers iteratively seek, filter, read, and extract information. When using multiple information sources and different applications for information processing, re-examination of activities for validation of previous decisions or re-discovery of previously used information sources is challenging. In this paper, we present a novel representation of cross-application histories to support recall of past operations and re-discovery of information resources. Our graphical history consists of a cross-scale visualization combining an overview node-link diagram of used desktop resources with nested (animated) snapshot sequences, based on a recording of the visual screen output during the users’ desktop work. This representation makes key elements of the users’ tasks visually stand out, while exploiting the power of visual memory to recover subtle details of their activities. In a preliminary study, users found our graphical history helpful to recall details of an information foraging task and commented positively on the ability to expand overview nodes into snapshot and video sequences.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Amirkhanov-2014-HSH.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Amirkhanov-2014-HSH.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Amirkhanov-2014-HSH" class="col-sm-8"> <div class="title">The Haunted Swamps of Heuristics: Uncertainty in Problem Solving</div> <div class="author"> Artem Amirkhanov, <em>Stefan Bruckner</em>, Christoph Heinzl, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Scientific Visualization: Uncertainty, Multifield, Biomedical, and Scalable Visualization</em>, Sep 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-1-4471-6497-5_5" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Amirkhanov-2014-HSH.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In scientific visualization the key task of research is the provision of insight into a problem. Finding the solution to a problem may be seen as finding a path through some rugged terrain which contains mountains, chasms, swamps, and few flatlands. This path - an algorithm discovered by the researcher - helps users to easily move around this unknown area. If this way is a wide road paved with stones it will be used for a long time by many travelers. However, a narrow footpath leading through deep forests and deadly swamps will attract only a few adventure seekers. There are many different paths with different levels of comfort, length, and stability, which are uncertain during the research process. Finding a systematic way to deal with this uncertainty can greatly assist the search for a safe path which is in our case the development of a suitable visualization algorithm for a specific problem. In this work we will analyze the sources of uncertainty in heuristically solving visualization problems and will propose directions to handle these uncertainties.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Parulek-2014-CLV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Parulek-2014-CLV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Parulek-2014-CLV" class="col-sm-8"> <div class="title">Continuous Levels-of-Detail and Visual Abstraction for Seamless Molecular Visualization</div> <div class="author"> Julius Parulek, Daniel Jönsson, Timo Ropinski, <em>Stefan Bruckner</em>, Anders Ynnerman, and Ivan Viola </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Sep 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.12349" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Parulek-2014-CLV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Molecular visualization is often challenged with rendering of large molecular structures in real time. We introduce a novel approach that enables us to show even large protein complexes. Our method is based on the level-of-detail concept, where we exploit three different abstractions combined in one visualization. Firstly, molecular surface abstraction exploits three different surfaces, solvent-excluded surface (SES), Gaussian kernels and van der Waals spheres, combined as one surface by linear interpolation. Secondly, we introduce three shading abstraction levels and a method for creating seamless transitions between these representations. The SES representation with full shading and added contours stands in focus while on the other side a sphere representation of a cluster of atoms with constant shading and without contours provide the context. Thirdly, we propose a hierarchical abstraction based on a set of clusters formed on molecular atoms. All three abstraction models are driven by one importance function classifying the scene into the near-, mid- and far-field. Moreover, we introduce a methodology to render the entire molecule directly using the A-buffer technique, which further improves the performance. The rendering performance is evaluated on series of molecules of varying atom counts.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Pfister-2014-VIC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Pfister-2014-VIC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Pfister-2014-VIC" class="col-sm-8"> <div class="title">Visualization in Connectomics</div> <div class="author"> Hanspeter Pfister, Verena Kaynig, Charl P. Botha, <em>Stefan Bruckner</em>, Vincent J. Dercksen, Hans-Christian Hege, and Jos B. T. M. Roerdink </div> <div class="periodical"> <em>In Scientific Visualization: Uncertainty, Multifield, Biomedical, and Scalable Visualization</em>, Sep 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-1-4471-6497-5_21" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Pfister-2014-VIC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Connectomics is a branch of neuroscience that attempts to create a connectome, i.e., a complete map of the neuronal system and all connections between neuronal structures. This representation can be used to understand how functional brain states emerge from their underlying anatomical structures and how dysfunction and neuronal diseases arise. We review the current state-of-the-art of visualization and image processing techniques in the field of connectomics and describe a number of challenges. After a brief summary of the biological background and an overview of relevant imaging modalities, we review current techniques to extract connectivity information from image data at macro-, meso- and microscales. We also discuss data integration and neural network modeling, as well as the visualization, analysis and comparison of brain networks.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Solteszova-2014-VPS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Solteszova-2014-VPS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Solteszova-2014-VPS" class="col-sm-8"> <div class="title">Visibility-Driven Processing of Streaming Volume Data</div> <div class="author"> Veronika Šoltészová, Åsmund Birkeland, Ivan Viola, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Proceedings of VCBM</em>, Vienna, Austria, Sep 2014 </div> <div class="periodical"> Best Paper Award at VCBM 2014 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/vcbm.20141198" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Solteszova-2014-VPS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=WJgc6BX1qig" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In real-time volume data acquisition, such as 4D ultrasound, the raw data is challenging to visualize directly without additional processing. Noise removal and feature detection are common operations, but many methods are too costly to compute over the whole volume when dealing with live streamed data. In this paper, we propose a visibility-driven processing scheme for handling costly on-the-fly processing of volumetric data in real-time. In contrast to the traditional visualization pipeline, our scheme utilizes a fast computation of the potentially visible subset of voxels which significantly reduces the amount of data required to process. As filtering operations modify the data values which may affect their visibility, our method for visibility-mask generation ensures that the set of elements deemed visible does not change after processing. Our approach also exploits the visibility information for the storage of intermediate values when multiple operations are performed in sequence, and can therefore significantly reduce the memory overhead of longer filter pipelines. We provide a thorough technical evaluation of the approach and demonstrate it on several typical scenarios where on-the-fly processing is required.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Swoboda-2014-VQA.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Swoboda-2014-VQA.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Swoboda-2014-VQA" class="col-sm-8"> <div class="title">Visual and Quantitative Analysis of Higher Order Arborization Overlaps for Neural Circuit Research</div> <div class="author"> Nicolas Swoboda, Judith Moosburner, <em>Stefan Bruckner</em>, Jai Y. Yu, Barry J. Dickson, and Katja Bühler </div> <div class="periodical"> <em>In Proceedings of VCBM</em>, Vienna, Austria, Sep 2014 </div> <div class="periodical"> Best Paper Honorable Mention at VCBM 2014 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/vcbm.20141189" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Swoboda-2014-VQA.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=iW2iVppPnsE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Neuroscientists investigate neural circuits in the brain of the common fruit fly Drosophila melanogaster to discover how complex behavior is generated. Hypothesis building on potential connections between individual neurons is an essential step in the discovery of circuits that govern a specific behavior. Overlaps of arborizations of two or more neurons indicate a potential anatomical connection, i.e. the presence of joint synapses responsible for signal transmission between neurons. Obviously, the number of higher order overlaps (i.e. overlaps of three and more arborizations) increases exponentially with the number of neurons under investigation making it almost impossible to precompute quantitative information for all possible combinations. Thus, existing solutions are restricted to pairwise comparison of overlaps as they are relying on precomputed overlap quantification. Analyzing overlaps by visual inspection of more than two arborizations in 2D sections or in 3D is impeded by visual clutter or occlusion. This work contributes a novel tool that complements existing methods for potential connectivity exploration by providing for the first time the possibility to compute and visualize higher order arborization overlaps on the fly and to interactively explore this information in its spatial anatomical context and on a quantitative level. Qualitative evaluation with neuroscientists and non-expert users demonstrated the utility and usability of the tool.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Kolesar-2014-IPT.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Kolesar-2014-IPT.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kolesar-2014-IPT" class="col-sm-8"> <div class="title">Illustrating Polymerization using Three-level Model Fusion</div> <div class="author"> Ivan Kolesar, Julius Parulek, Ivan Viola, <em>Stefan Bruckner</em>, Anne-Kristin Stavrum, and Helwig Hauser </div> <div class="periodical"> <em>In Proceedings of IEEE BioVis</em>, Aug 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Kolesar-2014-IPT.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Research in cell biology is steadily contributing new knowledge about many different aspects of physiological processes like polymerization, both with respect to the involved molecular structures as well as their related function. Illustrations of the spatio-temporal development of such processes are not only used in biomedical education, but also can serve scientists as an additional platform for in-silico experiments. In this paper, we contribute a new, three-level modeling approach to illustrate physiological processes from the class of polymerization at different time scales. We integrate physical and empirical modeling, according to which approach suits the different involved levels of detail best, and we additionally enable a simple form of interactive steering while the process is illustrated. We demonstrate the suitability of our approach in the context of several polymerization processes and report from a first evaluation with domain experts.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Angelelli-2014-LUP.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Angelelli-2014-LUP.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Angelelli-2014-LUP" class="col-sm-8"> <div class="title">Live Ultrasound-based Particle Visualization of Blood Flow in the Heart</div> <div class="author"> Paolo Angelelli, Sten Roar Snare, Siri Ann Nyrnes, <em>Stefan Bruckner</em>, Helwig Hauser, and Lasse Løvstakken </div> <div class="periodical"> <em>In Proceedings of SCCG</em>, May 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/2643188.2643200" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Angelelli-2014-LUP.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We introduce an integrated method for the acquisition, processing and visualization of live, in-vivo blood flow in the heart. The method is based on ultrasound imaging, using a plane wave acquisition acquisition protocol, which produces high frame rate ensemble data that are efficiently processed to extract directional flow information not previously available based on conventional Doppler imaging. These data are then visualized using a tailored pathlet-based visualization approach, to convey the slice-contained dynamic movement of the blood in the heart. This is especially important when imaging patients with possible congenital heart diseases, who typically exhibit complex flow patterns that are challenging to interpret. With this approach, it now is possible for the first time to achieve a real-time integration-based visualization of 2D blood flow aspects based on ultrasonic imaging. We demonstrate our solution in the context of selected cases of congenital heart diseases in neonates, showing how our technique allows for a more accurate and intuitive visualization of shunt flow and vortices.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2013</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Auzinger-2013-VVC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Auzinger-2013-VVC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Auzinger-2013-VVC" class="col-sm-8"> <div class="title">Vessel Visualization using Curved Surface Reformation</div> <div class="author"> Thomas Auzinger, Gabriel Mistelbauer, Ivan Baclija, Rüdiger Schernthaner, Arnold Köchl, Michael Wimmer, Meister Eduard Gröller, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Dec 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2013.215" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Auzinger-2013-VVC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=rESIFaO_-Gs" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Schmidt-2013-VVA.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Schmidt-2013-VVA.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Schmidt-2013-VVA" class="col-sm-8"> <div class="title">VAICo: Visual Analysis for Image Comparison</div> <div class="author"> Johanna Schmidt, Meister Eduard Gröller, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Dec 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2013.213" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Schmidt-2013-VVA.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=wfBqKZLVszk" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Scientists, engineers, and analysts are confronted with ever larger and more complex sets of data, whose analysis poses special challenges. In many situations it is necessary to compare two or more datasets. Hence there is a need for comparative visualization tools to help analyze differences or similarities among datasets. In this paper an approach for comparative visualization for sets of images is presented. Well-established techniques for comparing images frequently place them side-by-side. A major drawback of such approaches is that they do not scale well. Other image comparison methods encode differences in images by abstract parameters like color. In this case information about the underlying image data gets lost. This paper introduces a new method for visualizing differences and similarities in large sets of images which preserves contextual information, but also allows the detailed analysis of subtle variations. Our approach identifies local changes and applies cluster analysis techniques to embed them in a hierarchy. The results of this process are then presented in an interactive web application which allows users to rapidly explore the space of differences and drill-down on particular features. We demonstrate the flexibility of our approach by applying it to multiple distinct domains.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Patel-2013-ICS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Patel-2013-ICS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Patel-2013-ICS" class="col-sm-8"> <div class="title">Instant Convolution Shadows for Volumetric Detail Mapping</div> <div class="author"> Daniel Patel, Veronika Šoltészová, Jan Martin Nordbotten, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>ACM Transactions on Graphics</em>, Sep 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/2492684" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Patel-2013-ICS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=lhGWgew3HXY,https://www.video.com/watch?v=XrhYjgQxfb0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In this article, we present a method for rendering dynamic scenes featuring translucent procedural volumetric detail with all-frequency soft shadows being cast from objects residing inside the view frustum. Our approach is based on an approximation of physically correct shadows from distant Gaussian area light sources positioned behind the view plane, using iterative convolution. We present a theoretical and empirical analysis of this model and propose an efficient class of convolution kernels which provide high quality at interactive frame rates. Our GPU-based implementation supports arbitrary volumetric detail maps, requires no precomputation, and therefore allows for real-time modi?cation of all rendering parameters.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Karimov-2013-VSV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Karimov-2013-VSV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Karimov-2013-VSV" class="col-sm-8"> <div class="title">ViviSection: Skeleton-based Volume Editing</div> <div class="author"> Alexey Karimov, Gabriel Mistelbauer, Johanna Schmidt, Peter Mindek, Elisabeth Schmidt, Timur Sharipov, <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Leipzig, Germany, Jun 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.12133" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Karimov-2013-VSV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=4s12ZbUyHiY" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Volume segmentation is important in many applications, particularly in the medical domain. Most segmentation techniques, however, work fully automatically only in very restricted scenarios and cumbersome manual editing of the results is a common task. In this paper, we introduce a novel approach for the editing of segmentation results. Our method exploits structural features of the segmented object to enable intuitive and robust correction and verification. We demonstrate that our new approach can significantly increase the segmentation quality even in difficult cases such as in the presence of severe pathologies.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Mindek-2013-VPE.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Mindek-2013-VPE.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Mindek-2013-VPE" class="col-sm-8"> <div class="title">Visual Parameter Exploration in GPU Shader Space</div> <div class="author"> Peter Mindek, <em>Stefan Bruckner</em>, Peter Rautek, and Meister Eduard Gröller </div> <div class="periodical"> <em>Journal of WSCG</em>, Jun 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Mindek-2013-VPE.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=Sk7EXvqCoxs" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>The wide availability of high-performance GPUs has made the use of shader programs in visualization ubiquitous.Understanding shaders is a challenging task. Frequently it is difficult to mentally reconstruct the nature and types of transformations applied to the underlying data during the visualization process. We propose a method for the visual analysis of GPU shaders, which allows the flexible exploration and investigation of algorithms, parameters, and their effects. We introduce a method for extracting feature vectors composed of several attributes of the shader, as well as a direct manipulation interface for assigning semantics to them. The user interactively classifies pixels of images which are rendered with the investigated shader. The two resulting classes, a positive class and a negative one, are employed to steer the visualization. Based on this information, we can extract a wide variety of additional attributes and visualize their relation to this classification. Our system allows an interactive exploration of shader space and we demonstrate its utility for several different applications.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Mistelbauer-2013-VVC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Mistelbauer-2013-VVC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Mistelbauer-2013-VVC" class="col-sm-8"> <div class="title">Vessel Visualization using Curvicircular Feature Aggregation</div> <div class="author"> Gabriel Mistelbauer, Anca Morar, Andrej Varchola, Rüdiger Schernthaner, Ivan Baclija, Arnold Köchl, Armin Kanitsar, <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Leipzig, Germany, Jun 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.12110" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Mistelbauer-2013-VVC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=WwF5GPOs1pA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Radiological investigations are common medical practice for the diagnosis of peripheral vascular diseases. Existing visualization methods such as Curved Planar Reformation (CPR) depict calcifications on vessel walls to determine if blood is still able to flow. While it is possible with conventional CPR methods to examine the whole vessel lumen by rotating around the centerline of a vessel, we propose Curvicircular Feature Aggregation (CFA), which aggregates these rotated images into a single view. By eliminating the need for rotation, vessels can be investigated by inspecting only one image. This method can be used as a guidance and visual analysis tool for treatment planning. We present applications of this technique in the medical domain and give feedback from radiologists.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Mindek-2013-CSE.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Mindek-2013-CSE.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Mindek-2013-CSE" class="col-sm-8"> <div class="title">Contextual Snapshots: Enriched Visualization with Interactive Spatial Annotations</div> <div class="author"> Peter Mindek, <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of SCCG</em>, Smolenice, Slovakia, May 2013 </div> <div class="periodical"> Best Paper Award at SCCG 2013 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/2508244.2508251" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Mindek-2013-CSE.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=djuqJgixUCs" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Spatial selections are a ubiquitous concept in visualization. By localizing particular features, they can be analyzed and compared in different views. However, the semantics of such selections are often dependent on other parameter settings and it can be difficult to reconstruct them without additional information. In this paper, we present the concept of contextual snapshots as an effective means for managing spatial selections in visualized data. The selections are automatically associated with the context in which they have been created. Contextual snapshots can be also used as the basis for interactive integrated and linked views, which enable in-place investigation and comparison of multiple visual representations of data. Our approach is implemented as a flexible toolkit with welldefined interfaces for integration into existing systems. We demonstrate the power and generality of our techniques by applying them to several distinct scenarios such as the visualization of simulation data and the analysis of historical documents.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2012</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Csebfalvi-2012-IOM.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Csebfalvi-2012-IOM.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Csebfalvi-2012-IOM" class="col-sm-8"> <div class="title">Illumination-Driven Opacity Modulation for Expressive Volume Rendering</div> <div class="author"> Balázs Csebfalvi, Balázs Tóth, <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of VMV</em>, Magdeburg, Germany, Nov 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/PE/VMV/VMV12/103-109" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Csebfalvi-2012-IOM.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=ZvB-Vb7aa4o" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Using classical volume visualization, typically a couple of isosurface layers are rendered semi-transparently to show the internal structures contained in the data. However, the opacity transfer function is often difficult to specify such that all the isosurfaces are of high contrast and sufficiently perceivable. In this paper, we propose a volumerendering technique which ensures that the different layers contribute to fairly different regions of the image space. Since the overlapping between the effected regions is reduced, an outer translucent isosurface does not decrease significantly the contrast of a partially hidden inner isosurface. Therefore, the layers of the data become visually well separated. Traditional transfer functions assign color and opacity values to the voxels depending on the density and the gradient. In contrast, we assign also different illumination directions to different materials, and modulate the opacities view-dependently based on the surface normals and the directions of the light sources, which are fixed to the viewing angle. We will demonstrate that this model allows an expressive visualization of volumetric data.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Ford-2012-HRV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Ford-2012-HRV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Ford-2012-HRV" class="col-sm-8"> <div class="title">HeartPad: Real-Time Visual Guidance for Cardiac Ultrasound</div> <div class="author"> Steven Ford, Ivan Viola, <em>Stefan Bruckner</em>, Hans Torp, and Gabriel Kiss </div> <div class="periodical"> <em>In Proceedings of WASA</em>, Nov 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/2425296.2425326" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Ford-2012-HRV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=2d3G7ig-yiQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Medical ultrasound is a challenging modality when it comes to image interpretation. The goal we address in this work is to assist the ultrasound examiner and partially alleviate the burden of interpretation. We propose to address this goal with visualization that provides clear cues on the orientation and the correspondence between anatomy and the data being imaged. Our system analyzes the stream of 3D ultrasound data and in real-time identifies distinct features that are basis for a dynamically deformed mesh model of the heart. The heart mesh is composited with the original ultrasound data to create the data-to-anatomy correspondence. The visualization is broadcasted over the internet allowing, among other opportunities, a direct visualization on the patient on a tablet computer. The examiner interacts with the transducer and with the visualization parameters on the tablet. Our system has been characterized by domain specialist as useful in medical training and for navigating occasional ultrasound users.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Ropinski-2012-UBT.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Ropinski-2012-UBT.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Ropinski-2012-UBT" class="col-sm-8"> <div class="title">Unified Boundary-Aware Texturing for Interactive Volume Rendering</div> <div class="author"> Timo Ropinski, Stefan Diepenbrock, <em>Stefan Bruckner</em>, Klaus Hinrichs, and Meister Eduard Gröller </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Nov 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2011.285" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Ropinski-2012-UBT.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=kieFLOz22Dg" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In this paper, we describe a novel approach for applying texture mapping to volumetric data sets. In contrast to previous approaches, the presented technique enables a unified integration of 2D and 3D textures and thus allows to emphasize material boundaries as well as volumetric regions within a volumetric data set at the same time. One key contribution of this paper is a parametrization technique for volumetric data sets, which takes into account material boundaries and volumetric regions. Using this technique, the resulting parametrizations of volumetric data sets enable texturing effects which create a higher degree of realism in volume rendered images. We evaluate the quality of the parametrization and demonstrate the usefulness of the proposed concepts by combining volumetric texturing with volumetric lighting models to generate photorealistic volume renderings. Furthermore, we show the applicability in the area of illustrative visualization.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Mistelbauer-2012-SSV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Mistelbauer-2012-SSV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Mistelbauer-2012-SSV" class="col-sm-8"> <div class="title">Smart Super Views - A Knowledge-Assisted Interface for Medical Visualization</div> <div class="author"> Gabriel Mistelbauer, Hamed Bouzari, Rüdiger Schernthaner, Ivan Baclija, Arnold Köchl, <em>Stefan Bruckner</em>, Milos Srámek, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of IEEE VAST</em>, Seattle, WA, USA, Oct 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/VAST.2012.6400555" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Mistelbauer-2012-SSV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=cZREOedW7c4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Due to the ever growing volume of acquired data and information, users have to be constantly aware of the methods for their exploration and for interaction. Of these, not each might be applicable to the data at hand or might reveal the desired result. Owing to this, innovations may be used inappropriately and users may become skeptical. In this paper we propose a knowledge-assisted interface for medical visualization, which reduces the necessary effort to use new visualization methods, by providing only the most relevant ones in a smart way. Consequently, we are able to expand such a system with innovations without the users to worry about when, where, and especially how they may or should use them. We present an application of our system in the medical domain and give qualitative feedback from domain experts.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Birkeland-2012-IMC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Birkeland-2012-IMC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Birkeland-2012-IMC" class="col-sm-8"> <div class="title">Illustrative Membrane Clipping</div> <div class="author"> Åsmund Birkeland, <em>Stefan Bruckner</em>, Andrea Brambilla, and Ivan Viola </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Vienna, Austria, Jun 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/j.1467-8659.2012.03083.x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Birkeland-2012-IMC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=I89_%E2%80%93zul6c" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Clipping is a fast, common technique for resolving occlusions. It only requires simple interaction, is easily understandable, and thus has been very popular for volume exploration. However, a drawback of clipping is that the technique indiscriminately cuts through features. Illustrators, for example, consider the structures in the vicinity of the cut when visualizing complex spatial data and make sure that smaller structures near the clipping plane are kept in the image and not cut into fragments. In this paper we present a new technique, which combines the simple clipping interaction with automated selective feature preservation using an elastic membrane. In order to prevent cutting objects near the clipping plane, the deformable membrane uses underlying data properties to adjust itself to salient structures. To achieve this behaviour, we translate data attributes into a potential field which acts on the membrane, thus moving the problem of deformation into the soft-body dynamics domain. This allows us to exploit existing GPU-based physics libraries which achieve interactive frame rates. For manual adjustment, the user can insert additional potential fields, as well as pinning the membrane to interesting areas. We demonstrate that our method can act as a flexible and non-invasive replacement of traditional clipping planes.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Herghelegiu-2012-BPV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Herghelegiu-2012-BPV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Herghelegiu-2012-BPV" class="col-sm-8"> <div class="title">Biopsy Planner - Visual Analysis for Needle Pathway Planning in Deep Seated Brain Tumor Biopsy</div> <div class="author"> Paul Herghelegiu, Vasile Manta, Radu Perin, <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Vienna, Austria, Jun 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/j.1467-8659.2012.03101.x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Herghelegiu-2012-BPV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=PBEv-D_0Zm8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Biopsies involve taking samples from living tissue using a biopsy needle. In current clinical practice they are a first mandatory step before any further medical actions are planned. Performing a biopsy on a deep seated brain tumor requires considerable time for establishing and validating the desired biopsy needle pathway to avoid damage. In this paper, we present a system for the visualization, analysis, and validation of biopsy needle pathways. Our system uses a multi-level approach for identifying stable needle placements which minimize the risk of hitting blood vessels. This is one of the major dangers in this type of intervention. Our approach helps in identifying and visualizing the point on the pathway that is closest to a surrounding blood vessel, requiring a closer inspection by the neurosurgeon. An evaluation by medical experts is performed to demonstrate the utility of our system.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2012-VEA-Thesis.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2012-VEA-Thesis.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2012-VEA-Thesis" class="col-sm-8"> <div class="title">Visual Exploration and Analysis of Volumetric Data</div> <div class="author"> <em>Stefan Bruckner</em> </div> <div class="periodical"> Mar 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Bruckner-2012-VEA-Thesis.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Information technology has led to a rapid increase in the amount of data that arise in areas such as biology, medicine, climate science, and engineering. In many cases, these data are volumetric in nature, i.e., they describe the distribution of one or several quantities over a region in space. Volume visualization is the field of research which investigates the transformation of such data sets into images for purposes such as understanding structure or identifying features. This thesis presents work to aid this process by improving the interactive depiction, analysis, and exploration of volumetric data.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2011</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Haidacher-2011-VAM.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Haidacher-2011-VAM.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Haidacher-2011-VAM" class="col-sm-8"> <div class="title">Volume Analysis Using Multimodal Surface Similarity</div> <div class="author"> Martin Haidacher, <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Providence, Rhode Island, USA, Oct 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2011.258" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Haidacher-2011-VAM.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=x9ZTUssg8Fk" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>The combination of volume data acquired by multiple modalities has been recognized as an important but challenging task. Modalities often differ in the structures they can delineate and their joint information can be used to extend the classification space. However, they frequently exhibit differing types of artifacts which makes the process of exploiting the additional information non-trivial. In this paper, we present a framework based on an information-theoretic measure of isosurface similarity between different modalities to overcome these problems. The resulting similarity space provides a concise overview of the differences between the two modalities, and also serves as the basis for an improved selection of features. Multimodal classification is expressed in terms of similarities and dissimilarities between the isosurfaces of individual modalities, instead of data value combinations. We demonstrate that our approach can be used to robustly extract features in applications such as dual energy computed tomography of parts in industrial manufacturing.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Patel-2011-PEA.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Patel-2011-PEA.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Patel-2011-PEA" class="col-sm-8"> <div class="title">PhD Education Through Apprenticeship</div> <div class="author"> Daniel Patel, Meister Eduard Gröller, and <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Proceedings of Eurographics (Education Papers)</em>, Llandudno, United Kingdom, Apr 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Patel-2011-PEA.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We describe and analyze the PhD education in the visualization group at the Vienna University of Technology and set the education in a larger perspective. Four central mechanisms drive the PhD education in Vienna. They are: to require an article-based PhD; to give the student freedom to choose research direction; to let students work in shared offices towards joint deadlines; and to involve students in reviewing articles. This paper describes these mechanisms in detail and illustrates their effect.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2010</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Sikachev-2010-DFC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Sikachev-2010-DFC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Sikachev-2010-DFC" class="col-sm-8"> <div class="title">Dynamic Focus+Context for Volume Rendering</div> <div class="author"> Peter Sikachev, Peter Rautek, <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of VMV</em>, Siegen, Germany, Nov 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/PE/VMV/VMV10/331-338" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Sikachev-2010-DFC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=6x-gVBHYAcA,https://www.video.com/watch?v=TgotxmoepB8,https://www.video.com/watch?v=8K67zA8pbAo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Interactive visualization is widely used in many applications for efficient representation of complex data. Many techniques make use of the focus+context approach in a static manner. These techniques do not fully make use of the interaction semantics. In this paper we present a dynamic focus+context approach that highlights salient features during user interaction. We explore rotation, panning, and zooming interaction semantics and propose several methods of changing visual representations, based on a suggested engagement-estimation method. We use DVR-MIP interpolation and a radial opacity-change approach, exploring rotation, panning, and zooming semantics. Our approach adds short animations during user interaction that help to explore the data efficiently and aid the user in the detection of unknown features.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2010-RES.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2010-RES.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2010-RES" class="col-sm-8"> <div class="title">Result-Driven Exploration of Simulation Parameter Spaces for Visual Effects Design</div> <div class="author"> <em>Stefan Bruckner</em>, and Torsten Möller </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Salt Lake City, Utah, USA, Oct 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2010.190" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2010-RES.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=JunXyxULCpo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Graphics artists commonly employ physically-based simulation for the generation of effects such as smoke, explosions, and similar phenomena. The task of finding the correct parameters for a desired result, however, is difficult and time-consuming as current tools provide little to no guidance. In this paper, we present a new approach for the visual exploration of such parameter spaces. Given a three-dimensional scene description, we utilize sampling and spatio-temporal clustering techniques to generate a concise overview of the achievable variations and their temporal evolution. Our visualization system then allows the user to explore the simulation space in a goal-oriented manner. Animation sequences with a set of desired characteristics can be composed using a novel search-by-example approach and interactive direct volume rendering is employed to provide instant visual feedback. A user study was performed to evaluate the applicability of our system in production use.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2010-HVC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2010-HVC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2010-HVC" class="col-sm-8"> <div class="title">Hybrid Visibility Compositing and Masking for Illustrative Rendering</div> <div class="author"> <em>Stefan Bruckner</em>, Peter Rautek, Ivan Viola, Mike Roberts, Mario Costa Sousa, and Meister Eduard Gröller </div> <div class="periodical"> <em>Computers &amp; Graphics</em>, Aug 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.cag.2010.04.003" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2010-HVC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=V-Jbgpd9OjU,https://www.video.com/watch?v=Tsc30U4x3ic,https://www.video.com/watch?v=I4x5QtG25Tc" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In this paper, we introduce a novel framework for the compositing of interactively rendered 3D layers tailored to the needs of scientific illustration. Currently, traditional scientific illustrations are produced in a series of composition stages, combining different pictorial elements using 2D digital layering. Our approach extends the layer metaphor into 3D without giving up the advantages of 2D methods. The new compositing approach allows for effects such as selective transparency, occlusion overrides, and soft depth buffering. Furthermore, we show how common manipulation techniques such as masking can be integrated into this concept. These tools behave just like in 2D, but their influence extends beyond a single viewpoint. Since the presented approach makes no assumptions about the underlying rendering algorithms, layers can be generated based on polygonal geometry, volumetric data, point based representations, or others. Our implementation exploits current graphics hardware and permits real-time interaction and rendering.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2010-IFC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2010-IFC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2010-IFC" class="col-sm-8"> <div class="title">Illustrative Focus+Context Approaches in Interactive Volume Visualization</div> <div class="author"> <em>Stefan Bruckner</em>, Meister Eduard Gröller, Klaus Mueller, Bernhard Preim, and Deborah Silver </div> <div class="periodical"> <em>In Scientific Visualization: Advanced Concepts</em>, Aug 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.4230/DFU.SciViz.2010.136" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2010-IFC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Illustrative techniques are a new and exciting direction in visualization research. Traditional techniques which have been used by scientific illustrators for centuries are re-examined under the light of modern computer technology. In this paper, we discuss the use of the focus+context concept for the illustrative visualization of volumetric data. We give an overview of the state-of-the-art and discuss recent approaches which employ this concept in novel ways.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2010-ISM.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2010-ISM.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2010-ISM" class="col-sm-8"> <div class="title">Isosurface Similarity Maps</div> <div class="author"> <em>Stefan Bruckner</em>, and Torsten Möller </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Bordeaux, France, Jun 2010 </div> <div class="periodical"> Best Paper Award at EuroVis 2010 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/j.1467-8659.2009.01689.x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2010-ISM.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=NZFqx4QceCA,https://www.video.com/watch?v=kQO8fTJJxVg,https://www.video.com/watch?v=KDIbmfOAW00" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In this paper, we introduce the concept of isosurface similarity maps for the visualization of volume data. Isosurface similarity maps present structural information of a volume data set by depicting similarities between individual isosurfaces quantified by a robust information-theoretic measure. Unlike conventional histograms, they are not based on the frequency of isovalues and/or derivatives and therefore provide complementary information. We demonstrate that this new representation can be used to guide transfer function design and visualization parameter specification. Furthermore, we use isosurface similarity to develop an automatic parameter-free method for identifying representative isovalues. Using real-world data sets, we show that isosurface similarity maps can be a useful addition to conventional classification techniques.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Solteszova-2010-MOS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Solteszova-2010-MOS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Solteszova-2010-MOS" class="col-sm-8"> <div class="title">A Multidirectional Occlusion Shading Model for Direct Volume Rendering</div> <div class="author"> Veronika Šoltészová, Daniel Patel, <em>Stefan Bruckner</em>, and Ivan Viola </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Bordeaux, France, Jun 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/j.1467-8659.2009.01695.x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Solteszova-2010-MOS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=V4y0BVKV_bw" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In this paper, we present a novel technique which simulates directional light scattering for more realistic interactive visualization of volume data. Our method extends the recent directional occlusion shading model by enabling light source positioning with practically no performance penalty. Light transport is approximated using a tilted cone-shaped function which leaves elliptic footprints in the opacity buffer during slice-based volume rendering. We perform an incremental blurring operation on the opacity buffer for each slice in front-to-back order. This buffer is then used to define the degree of occlusion for the subsequent slice. Our method is capable of generating high-quality soft shadowing effects, allows interactive modification of all illumination and rendering parameters, and requires no pre-computation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Haidacher-2010-VVS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Haidacher-2010-VVS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Haidacher-2010-VVS" class="col-sm-8"> <div class="title">Volume Visualization based on Statistical Transfer-Function Spaces</div> <div class="author"> Martin Haidacher, Daniel Patel, <em>Stefan Bruckner</em>, Armin Kanitsar, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of IEEE PacificVis</em>, Taipei, Taiwan, Mar 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/PACIFICVIS.2010.5429615" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Haidacher-2010-VVS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=firkkbHdZ5o" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>It is a difficult task to design transfer functions for noisy data. In traditional transfer-function spaces, data values of different materials overlap. In this paper we introduce a novel statistical transfer-function space which in the presence of noise, separates different materials in volume data sets. Our method adaptively estimates statistical properties, i.e. the mean value and the standard deviation, of the data values in the neighborhood of each sample point. These properties are used to define a transfer-function space which enables the distinction of different materials. Additionally, we present a novel approach for interacting with our new transfer-function space which enables the design of transfer functions based on statistical properties. Furthermore, we demonstrate that statistical information can be applied to enhance visual appearance in the rendering process. We compare the new method with 1D, 2D, and LH transfer functions to demonstrate its usefulness.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Patel-2010-SVV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Patel-2010-SVV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Patel-2010-SVV" class="col-sm-8"> <div class="title">Seismic Volume Visualization for Horizon Extraction</div> <div class="author"> Daniel Patel, <em>Stefan Bruckner</em>, Ivan Viola, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of IEEE PacificVis</em>, Taipei, Taiwan, Mar 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/PACIFICVIS.2010.5429605" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Patel-2010-SVV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=YXg4LZsTQdc" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Seismic horizons indicate change in rock properties and are central in geoscience interpretation. Traditional interpretation systems involve time consuming and repetitive manual volumetric seeding for horizon growing. We present a novel system for rapidly interpreting and visualizing seismic volumetric data. First we extract horizon surface-parts by preprocessing the seismic data. Then during interaction the user can assemble in realtime the horizon parts into horizons. Traditional interpretation systems use gradient-based illumination models in the rendering of the seismic volume and polygon rendering of horizon surfaces. We employ realtime gradientfree forward-scattering in the rendering of seismic volumes yielding results similar to high-quality global illumination. We use an implicit surface representation of horizons allowing for a seamless integration of horizon rendering and volume rendering. We present a collection of novel techniques constituting an interpretation and visualization system highly tailored to seismic data interpretation.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2009</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2009-BVQ.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2009-BVQ.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2009-BVQ" class="col-sm-8"> <div class="title">BrainGazer - Visual Queries for Neurobiology Research</div> <div class="author"> <em>Stefan Bruckner</em>, Veronika Šoltészová, Meister Eduard Gröller, Jiří Hladůvka, Katja Bühler, Jai Yu, and Barry Dickson </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Atlantic City, New Jersey, USA, Nov 2009 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2009.121" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2009-BVQ.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=LB5t3RtLifk" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Neurobiology investigates how anatomical and physiological relationships in the nervous system mediate behavior. Molecular genetic techniques, applied to species such as the common fruit fly Drosophila melanogaster, have proven to be an important tool in this research. Large databases of transgenic specimens are being built and need to be analyzed to establish models of neural information processing. In this paper we present an approach for the exploration and analysis of neural circuits based on such a database. We have designed and implemented BrainGazer, a system which integrates visualization techniques for volume data acquired through confocal microscopy as well as annotated anatomical structures with an intuitive approach for accessing the available information. We focus on the ability to visually query the data based on semantic as well as spatial relationships. Additionally, we present visualization techniques for the concurrent depiction of neurobiological volume data and geometric objects which aim to reduce visual clutter. The described system is the result of an ongoing interdisciplinary collaboration between neurobiologists and visualization researchers.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2009-IVV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2009-IVV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2009-IVV" class="col-sm-8"> <div class="title">Instant Volume Visualization using Maximum Intensity Difference Accumulation</div> <div class="author"> <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Berlin, Germany, Jun 2009 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/j.1467-8659.2009.01474.x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2009-IVV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=lNwZJXxoLTg,https://www.video.com/watch?v=AR-Zp3S35hs,https://www.video.com/watch?v=xk4J8bkI2-Y,https://www.video.com/watch?v=XApq2rGKMR8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>It has long been recognized that transfer function setup for Direct Volume Rendering (DVR) is crucial to its usability. However, the task of finding an appropriate transfer function is complex and time-consuming even for experts. Thus, in many practical applications simpler techniques which do not rely on complex transfer functions are employed. One common example is Maximum Intensity Projection (MIP) which depicts the maximum value along each viewing ray. In this paper, we introduce Maximum Intensity Difference Accumulation (MIDA), a new approach which combines the advantages of DVR and MIP. Like MIP, MIDA exploits common data characteristics and hence does not require complex transfer functions to generate good visualization results. It does, however, feature occlusion and shape cues similar to DVR. Furthermore, we show that MIDA - in addition to being a useful technique in its own right- can be used to smoothly transition between DVR and MIP in an intuitive manner. MIDA can be easily implemented using volume raycasting and achieves real-time performance on current graphics hardware.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Kohlmann-2009-CPV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Kohlmann-2009-CPV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kohlmann-2009-CPV" class="col-sm-8"> <div class="title">Contextual Picking of Volumetric Structures</div> <div class="author"> Peter Kohlmann, <em>Stefan Bruckner</em>, Armin Kanitsar, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of the IEEE PacificVis</em>, Peking, China, May 2009 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/PACIFICVIS.2009.4906855" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Kohlmann-2009-CPV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=SgyGwePAE7o" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>This paper presents a novel method for the interactive identification of contextual interest points within volumetric data by picking on a direct volume rendered image. In clinical diagnostics the points of interest are often located in the center of anatomical structures. In order to derive the volumetric position which allows a convenient examination of the intended structure, the system automatically extracts contextual meta information from the DICOM (Digital Imaging and Communications in Medicine) images and the setup of the medical workstation. Along a viewing ray for a volumetric picking, the ray profile is analyzed for structures which are similar to predefined templates from a knowledge base. We demonstrate with our results that the obtained position in 3D can be utilized to highlight a structure in 2D slice views, to interactively calculate centerlines of tubular objects, or to place labels at contextually-defined volumetric positions.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2008</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Haidacher-2008-ITF.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Haidacher-2008-ITF.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Haidacher-2008-ITF" class="col-sm-8"> <div class="title">Information-based Transfer Functions for Multimodal Visualization</div> <div class="author"> Martin Haidacher, <em>Stefan Bruckner</em>, Armin Kanitsar, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of VCBM</em>, Delft, Oct 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/VCBM/VCBM08/101-108" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Haidacher-2008-ITF.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Transfer functions are an essential part of volume visualization. In multimodal visualization at least two values exist at every sample point. Additionally, other parameters, such as gradient magnitude, are often retrieved for each sample point. To find a good transfer function for this high number of parameters is challenging because of the complexity of this task. In this paper we present a general information-based approach for transfer function design in multimodal visualization which is independent of the used modality types. Based on information theory, the complex multi-dimensional transfer function space is fused to allow utilization of a well-known 2D transfer function with a single value and gradient magnitude as parameters. Additionally, a quantity is introduced which enables better separation of regions with complementary information. The benefit of the new method in contrast to other techniques is a transfer function space which is easy to understand and which provides a better separation of different tissues. The usability of the new approach is shown on examples of different modalities.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Rautek-2008-IVN.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Rautek-2008-IVN.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Rautek-2008-IVN" class="col-sm-8"> <div class="title">Illustrative Visualization: New Technology or Useless Tautology?</div> <div class="author"> Peter Rautek, <em>Stefan Bruckner</em>, Meister Eduard Gröller, and Ivan Viola </div> <div class="periodical"> <em>ACM SIGGRAPH Computer Graphics</em>, Aug 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/1408626.1408633" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Rautek-2008-IVN.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>The computer graphics group at TU Vienna has created some of most beautiful and effective illustrative visualizations. In this article, they share with us their unique perspective on illustrative visualization.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Ruiz-2008-SEV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Ruiz-2008-SEV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Ruiz-2008-SEV" class="col-sm-8"> <div class="title">Similarity-based Exploded Views</div> <div class="author"> Marc Ruiz, Ivan Viola, Imma Boada, <em>Stefan Bruckner</em>, Miquel Feixas, and Mateu Sbert </div> <div class="periodical"> <em>In Proceedings of Smart Graphics</em>, Rennes, France, Aug 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-540-85412-8_14" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Ruiz-2008-SEV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Exploded views are often used in illustration to overcome the problem of occlusion when depicting complex structures. In this paper, we propose a volume visualization technique inspired by exploded views that partitions the volume into a number of parallel slabs and shows them apart from each other. The thickness of slabs is driven by the similarity between partitions. We use an information-theoretic technique for the generation of exploded views. First, the algorithm identifies the viewpoint from which the structure is the highest. Then, the partition of the volume into the most informative slabs for exploding is obtained using two complementary similarity-based strategies. The number of slabs and the similarity parameter are freely adjustable by the user.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2008-IVV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2008-IVV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2008-IVV" class="col-sm-8"> <div class="title">Integrating Volume Visualization Techniques Into Medical Applications</div> <div class="author"> <em>Stefan Bruckner</em>, Peter Kohlmann, Armin Kanitsar, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of ISBI</em>, Paris, France, May 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ISBI.2008.4541122" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2008-IVV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>One of the main obstacles in integrating 3D volume visualization in the clinical workflow is the time-consuming process of adjusting parameters such as viewpoint, transfer functions, and clipping planes required to generate a diagnostically relevant image. Current applications therefore make scarce use of volume rendering and instead primarily employ 2D views generated through standard techniques such as multi-planar reconstruction (MPR). However, in many cases 3D renditions can supply additional useful information. This paper discusses ongoing work which aims to improve the integration of 3D visualization into the diagnostic workflow by automatically generating meaningful renditions based on minimal user interaction. A method for automatically generating 3D views for structures in 2D slices based on a single picking interaction is presented.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Kohlmann-2008-LEI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Kohlmann-2008-LEI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kohlmann-2008-LEI" class="col-sm-8"> <div class="title">LiveSync++: Enhancements of an Interaction Metaphor</div> <div class="author"> Peter Kohlmann, <em>Stefan Bruckner</em>, Armin Kanitsar, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of Graphics Interface</em>, Windsor, Ontario, Canada, May 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Kohlmann-2008-LEI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=_Jt8ezi7yjs" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>The LiveSync interaction metaphor allows an efficient and non-intrusive integration of 2D and 3D visualizations in medical workstations. This is achieved by synchronizing the 2D slice view with the volumetric view. The synchronization is initiated by a simple picking on a structure of interest in the slice view. In this paper we present substantial enhancements of the existing concept to improve its usability. First, an efficient parametrization for the derived parameters is presented, which allows hierarchical refinement of the search space for good views. Second, the extraction of the feature of interest is performed in a way, which is adapting to the volumetric extent of the feature. The properties of the extracted features are utilized to adjust a predefined transfer function in a feature-enhancing manner. Third, a new interaction mode is presented, which allows the integration of more knowledge about the user-intended visualization, without increasing the interaction effort. Finally, a new clipping technique is integrated, which guarantees an unoccluded view on the structure of interest while keeping important contextual information.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Rautek-2008-ISI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Rautek-2008-ISI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Rautek-2008-ISI" class="col-sm-8"> <div class="title">Interaction-Dependent Semantics for Illustrative Volume Rendering</div> <div class="author"> Peter Rautek, <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Eindhoven, The Netherlands, May 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/j.1467-8659.2008.01216.x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Rautek-2008-ISI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=fHIl2A50Ico" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In traditional illustration the choice of appropriate styles and rendering techniques is guided by the intention of the artist. For illustrative volume visualizations it is difficult to specify the mapping between the 3D data and the visual representation that preserves the intention of the user. The semantic layers concept establishes this mapping with a linguistic formulation of rules that directly map data features to rendering styles. With semantic layers fuzzy logic is used to evaluate the user defined illustration rules in a preprocessing step. In this paper we introduce interaction-dependent rules that are evaluated for each frame and are therefore computationally more expensive. Enabling interaction-dependent rules, however, allows the use of a new class of semantics, resulting in more expressive interactive illustrations. We show that the evaluation of the fuzzy logic can be done on the graphics hardware enabling the efficient use of interaction-dependent semantics. Further we introduce the flat rendering mode and discuss how different rendering parameters are influenced by the rule base. Our approach provides high quality illustrative volume renderings at interactive frame rates, guided by the specification of illustration rules.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2008-IIV-Thesis.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2008-IIV-Thesis.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2008-IIV-Thesis" class="col-sm-8"> <div class="title">Interactive Illustrative Volume Visualization</div> <div class="author"> <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Vienna University of Technology, Austria</em>, Apr 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Bruckner-2008-IIV-Thesis.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Illustrations are essential for the effective communication of complex subjects. Their production, however, is a difficult and expensive task. In recent years, three-dimensional imaging has become a vital tool not only in medical diagnosis and treatment planning, but also in many technical disciplines (e.g., material inspection), biology, and archeology. Modalities such as X-Ray Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) produce high-resolution volumetric scans on a daily basis. It seems counter-intuitive that even though such a wealth of data is available, the production of an illustration should still require a mainly manual and time-consuming process. This thesis is devoted to the computer-assisted generation of illustrations directly from volumetric data using advanced visualization techniques. The concept of a direct volume illustration system is introduced for this purpose. Instead of requiring an additional modeling step, this system allows the designer of an illustration to work directly on the measured data. Abstraction, a key component of traditional illustrations, is used in order to reduce visual clutter, emphasize important structures, and reveal hidden detail. Low-level abstraction techniques are concerned with the appearance of objects and allow flexible artistic shading of structures in volumetric data sets. High-level abstraction techniques control which objects are visible. For this purpose, novel methods for the generation of ghosted and exploded views are introduced. The visualization techniques presented in this thesis employ the features of current graphics hardware to achieve interactive performance. The resulting system allows the generation of expressive illustrations directly from volumetric data with applications in medical training, patient education, and scientific communication.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2007</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2007-EDF.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2007-EDF.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2007-EDF" class="col-sm-8"> <div class="title">Enhancing Depth-Perception with Flexible Volumetric Halos</div> <div class="author"> <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Sacramento, California, USA, Oct 2007 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2007.70555" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2007-EDF.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=NvHfxX8wjE8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Volumetric data commonly has high depth complexity which makes it difficult to judge spatial relationships accurately. There are many different ways to enhance depth perception, such as shading, contours, and shadows. Artists and illustrators frequently employ halos for this purpose. In this technique, regions surrounding the edges of certain structures are darkened or brightened which makes it easier to judge occlusion. Based on this concept, we present a flexible method for enhancing and highlighting structures of interest using GPU-based direct volume rendering. Our approach uses an interactively defined halo transfer function to classify structures of interest based on data value, direction, and position. A feature-preserving spreading algorithm is applied to distribute seed values to neighboring locations, generating a controllably smooth field of halo intensities. These halo intensities are then mapped to colors and opacities using a halo profile function. Our method can be used to annotate features at interactive frame rates.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Kohlmann-2007-LDV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Kohlmann-2007-LDV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kohlmann-2007-LDV" class="col-sm-8"> <div class="title">LiveSync: Deformed Viewing Spheres for Knowledge-Based Navigation</div> <div class="author"> Peter Kohlmann, <em>Stefan Bruckner</em>, Armin Kanitsar, and Meister Eduard Gröller </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Sacramento, California, USA, Oct 2007 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2007.70576" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Kohlmann-2007-LDV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=vzoS6plGxzQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Although real-time interactive volume rendering is available even for very large data sets, this visualization method is used quite rarely in the clinical practice. We suspect this is because it is very complicated and time consuming to adjust the parameters to achieve meaningful results. The clinician has to take care of the appropriate viewpoint, zooming, transfer function setup, clipping planes and other parameters. Because of this, most often only 2D slices of the data set are examined. Our work introduces LiveSync, a new concept to synchronize 2D slice views and volumetric views of medical data sets. Through intuitive picking actions on the slice, the users define the anatomical structures they are interested in. The 3D volumetric view is updated automatically with the goal that the users are provided with expressive result images. To achieve this live synchronization we use a minimal set of derived information without the need for segmented data sets or data-specific pre-computations. The components we consider are the picked point, slice view zoom, patient orientation, viewpoint history, local object shape and visibility. We introduce deformed viewing spheres which encode the viewpoint quality for the components. A combination of these deformed viewing spheres is used to estimate a good viewpoint. Our system provides the physician with synchronized views which help to gain deeper insight into the medical data with minimal user interaction.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Rautek-2007-SLI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Rautek-2007-SLI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Rautek-2007-SLI" class="col-sm-8"> <div class="title">Semantic Layers for Illustrative Volume Rendering</div> <div class="author"> Peter Rautek, <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Sacramento, California, USA, Oct 2007 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2007.70591" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Rautek-2007-SLI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=c91m6ru5m0g" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Direct volume rendering techniques map volumetric attributes (e.g., density, gradient magnitude, etc.) to visual styles. Commonly this mapping is specified by a transfer function. The specification of transfer functions is a complex task and requires expert knowledge about the underlying rendering technique. In the case of multiple volumetric attributes and multiple visual styles the specification of the multi-dimensional transfer function becomes more challenging and non-intuitive. We present a novel methodology for the specification of a mapping from several volumetric attributes to multiple illustrative visual styles. We introduce semantic layers that allow a domain expert to specify the mapping in the natural language of the domain. A semantic layer defines the mapping of volumetric attributes to one visual style. Volumetric attributes and visual styles are represented as fuzzy sets. The mapping is specified by rules that are evaluated with fuzzy logic arithmetics. The user specifies the fuzzy sets and the rules without special knowledge about the underlying rendering technique. Semantic layers allow for a linguistic specification of the mapping from attributes to visual styles replacing the traditional transfer function specification.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2007-STF.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2007-STF.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2007-STF" class="col-sm-8"> <div class="title">Style Transfer Functions for Illustrative Volume Rendering</div> <div class="author"> <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Prague, Czech Republic, Sep 2007 </div> <div class="periodical"> 3rd Best Paper Award at Eurographics 2007 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/j.1467-8659.2007.01095.x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2007-STF.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=40SdXa7aAjI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Illustrative volume visualization frequently employs non-photorealistic rendering techniques to enhance important features or to suppress unwanted details. However, it is difficult to integrate multiple non-photorealistic rendering approaches into a single framework due to great differences in the individual methods and their parameters. In this paper, we present the concept of style transfer functions. Our approach enables flexible data-driven illumination which goes beyond using the transfer function to just assign colors and opacities. An image-based lighting model uses sphere maps to represent non-photorealistic rendering styles. Style transfer functions allow us to combine a multitude of different shading styles in a single rendering. We extend this concept with a technique for curvature-controlled style contours and an illustrative transparency model. Our implementation of the presented methods allows interactive generation of high-quality volumetric illustrations.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Kohlmann-2007-EBV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Kohlmann-2007-EBV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kohlmann-2007-EBV" class="col-sm-8"> <div class="title">Evaluation of a Bricked Volume Layout for a Medical Workstation based on Java</div> <div class="author"> Peter Kohlmann, <em>Stefan Bruckner</em>, Armin Kanitsar, and Meister Eduard Gröller </div> <div class="periodical"> <em>Journal of WSCG</em>, Plzen, Czech Republic, Jan 2007 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Kohlmann-2007-EBV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Volumes acquired for medical examination purposes are constantly increasing in size. For this reason, the computer’s memory is the limiting factor for visualizing the data. Bricking is a well-known concept used for rendering large data sets. The volume data is subdivided into smaller blocks to achieve better memory utilization. Until now, the vast majority of medical workstations use a linear volume layout. We implemented a bricked volume layout for such a workstation based on Java as required by our collaborative company partner to evaluate different common access patterns to the volume data. For rendering, we were mainly interested to see how the performance will differ from the traditional linear volume layout if we generate images of arbitrarily oriented slices via Multi-Planar Reformatting (MPR). Furthermore, we tested access patterns which are crucial for segmentation issues like a random access to data values and a simulated region growing. Our goal was to find out if it makes sense to change the volume layout of a medical workstation to benefit from bricking. We were also interested to identify the tasks where problems might occur if bricking is applied. Overall, our results show that it is feasible to use a bricked volume layout in the stringent context of a medical workstation implemented in Java.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2006</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2006-ICE.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2006-ICE.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2006-ICE" class="col-sm-8"> <div class="title">Illustrative Context-Preserving Exploration of Volume Data</div> <div class="author"> <em>Stefan Bruckner</em>, Sören Grimm, Armin Kanitsar, and Meister Eduard Gröller </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Nov 2006 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2006.96" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2006-ICE.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=a92NXYtJeT0,https://www.video.com/watch?v=OLEr5-O1jmY,https://www.video.com/watch?v=RSet7-n6Mc4,https://www.video.com/watch?v=w0U8lteEMOM,https://www.video.com/watch?v=csYsfKrQxN8,https://www.video.com/watch?v=3xduvvU6IAw" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In volume rendering it is very difficult to simultaneously visualize interior and exterior structures while preserving clear shape cues. Highly transparent transfer functions produce cluttered images with many overlapping structures, while clipping techniques completely remove possibly important context information. In this paper we present a new model for volume rendering, inspired by techniques from illustration. It provides a means of interactively inspecting the interior of a volumetric data set in a feature-driven way which retains context information. The context-preserving volume rendering model uses a function of shading intensity, gradient magnitude, distance to the eye point, and previously accumulated opacity to selectively reduce the opacity in less important data regions. It is controlled by two user-specified parameters. This new method represents an alternative to conventional clipping techniques, shares their easy and intuitive user control, but does not suffer from the drawback of missing context information.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2006-EVV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2006-EVV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2006-EVV" class="col-sm-8"> <div class="title">Exploded Views for Volume Data</div> <div class="author"> <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Sep 2006 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2006.140" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2006-EVV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=6jEqVrjaM3M" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Exploded views are an illustration technique where an object is partitioned into several segments. These segments are displaced to reveal otherwise hidden detail. In this paper we apply the concept of exploded views to volumetric data in order to solve the general problem of occlusion. In many cases an object of interest is occluded by other structures. While transparency or cutaways can be used to reveal a focus object, these techniques remove parts of the context information. Exploded views, on the other hand, do not suffer from this drawback. Our approach employs a force-based model: the volume is divided into a part configuration controlled by a number of forces and constraints. The focus object exerts an explosion force causing the parts to arrange according to the given constraints. We show that this novel and flexible approach allows for a wide variety of explosion-based visualizations including view-dependent explosions. Furthermore, we present a high-quality GPU-based volume ray casting algorithm for exploded views which allows rendering and interaction at several frames per second.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Rautek-2006-DHQ.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Rautek-2006-DHQ.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Rautek-2006-DHQ" class="col-sm-8"> <div class="title">D2VR: High Quality Volume Rendering of Projection-based Volumetric Data</div> <div class="author"> Peter Rautek, Balázs Csebfalvi, Sören Grimm, <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of EuroVis</em>, May 2006 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/VisSym/EuroVis06/211-218" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Rautek-2006-DHQ.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Volume rendering techniques are conventionally classified as either direct or indirect methods. Indirect methods require to transform the initial volumetric model into an intermediate geometrical model in order to efficiently visualize it. In contrast, direct volume rendering (DVR) methods can directly process the volumetric data. Modern CT scanners usually provide data as a set of samples on a rectilinear grid, which is computed from the measured projections by discrete tomographic reconstruction. Therefore the rectilinear grid can already be considered as an intermediate volume representation. In this paper we introduce direct direct volume rendering (D\textsuperscript2VR). D2VR does not require a rectilinear grid, since it is based on an immediate processing of the measured projections. Arbitrary samples for ray casting are reconstructed from the projections by using the Filtered Back-Projection algorithm. Our method removes a lossy resampling step from the classical volume rendering pipeline. It provides much higher accuracy than traditional grid-based resampling techniques do. Furthermore we also present a novel high-quality gradient estimation scheme, which is also based on the Filtered Back-Projection algorithm.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2005</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Coto-2005-MAC.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Coto-2005-MAC.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Coto-2005-MAC" class="col-sm-8"> <div class="title">MammoExplorer: An Advanced CAD Application for Breast DCE-MRI</div> <div class="author"> Ernesto Coto, Sören Grimm, <em>Stefan Bruckner</em>, Meister Eduard Gröller, Armin Kanitsar, and Omaira Rodriguez </div> <div class="periodical"> <em>In Proceedings of VMV</em>, Erlangen, Germany, Nov 2005 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Coto-2005-MAC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=6XBD1f1y2xs" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Currently X-ray mammography is the most widely used method for early detection of breast cancer. However, the use of Dynamic Contrast Enhanced MRI (DCE-MRI) has gained wider attention, since it considerably improves tumor detection and classification by analyzing the flow of contrast agent within the breast tissue. In this paper we present MammoExplorer, a CAD application that combines advanced interaction, segmentation and visualization techniques to explore Breast DCE-MRI data. Our application uses Brushing and Linking, Two-level Volume Rendering, Importance-driven Volume Rendering, and False Color Maps. In addition, we present Enhancement Scatterplots, a novel graphical representation of DCE-MRI data, novel segmentation approaches, and a new way to explore time-varying CE-MRI data.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2005-VIS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2005-VIS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2005-VIS" class="col-sm-8"> <div class="title">VolumeShop: An Interactive System for Direct Volume Illustration</div> <div class="author"> <em>Stefan Bruckner</em>, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of IEEE Visualization</em>, Minneapolis, USA, Oct 2005 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/VISUAL.2005.1532856" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2005-VIS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=1FZausY8dFw,https://www.video.com/watch?v=WB-4NHKSM4k,https://www.video.com/watch?v=Rzi6q6n5lRs,https://www.video.com/watch?v=0B_fVsBibZk" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Illustrations play a major role in the education process. Whether used to teach a surgical or radiologic procedure, to illustrate normal or aberrant anatomy, or to explain the functioning of a technical device, illustration significantly impacts learning. Although many specimens are readily available as volumetric data sets, particularly in medicine, illustrations are commonly produced manually as static images in a time-consuming process. Our goal is to create a fully dynamic three-dimensional illustration environment which directly operates on volume data. Single images have the aesthetic appeal of traditional illustrations, but can be interactively altered and explored. In this paper we present methods to realize such a system which combines artistic visual styles and expressive visualization techniques. We introduce a novel concept for direct multi-object volume visualization which allows control of the appearance of inter-penetrating objects via two-dimensional transfer functions. Furthermore, a unifying approach to efficiently integrate many non-photorealistic rendering models is presented. We discuss several illustrative concepts which can be realized by combining cutaways, ghosting, and selective deformation. Finally, we also propose a simple interface to specify objects of interest through three-dimensional volumetric painting. All presented methods are integrated into VolumeShop, an interactive hardware-accelerated application for direct volume illustration.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2005-ICV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2005-ICV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2005-ICV" class="col-sm-8"> <div class="title">Illustrative Context-Preserving Volume Rendering</div> <div class="author"> <em>Stefan Bruckner</em>, Sören Grimm, Armin Kanitsar, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of EuroVis</em>, May 2005 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/VisSym/EuroVis05/069-076" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Bruckner-2005-ICV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=Tc4E2oOD8Zg,https://www.video.com/watch?v=_8P_hVBoFeU,https://www.video.com/watch?v=0yxNoPjT6Ig,https://www.video.com/watch?v=EjG6E2WEO30" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In volume rendering it is very difficult to simultaneously visualize interior and exterior structures while preserving clear shape cues. Very transparent transfer functions produce cluttered images with many overlapping structures, while clipping techniques completely remove possibly important context information. In this paper we present a new model for volume rendering, inspired by techniques from illustration that provides a means of interactively inspecting the interior of a volumetric data set in a feature-driven way which retains context information. The context-preserving volume rendering model uses a function of shading intensity, gradient magnitude, distance to the eye point, and previously accumulated opacity to selectively reduce the opacity in less important data regions. It is controlled by two user-specified parameters. This new method represents an alternative to conventional clipping techniques, shares their easy and intuitive user control, but does not suffer from the drawback of missing context information.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2004</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Grimm-2004-FDM.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Grimm-2004-FDM.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Grimm-2004-FDM" class="col-sm-8"> <div class="title">Flexible Direct Multi-Volume Rendering in Interactive Scenes</div> <div class="author"> Sören Grimm, <em>Stefan Bruckner</em>, Armin Kanitsar, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of VMV</em>, Stanford, USA, Oct 2004 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Grimm-2004-FDM.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=pDskLE6cnFw,https://www.video.com/watch?v=VYKaSpsZd2s,https://www.video.com/watch?v=BGE640_Tw2U,https://www.video.com/watch?v=p-I0HWBv4Jc,https://www.video.com/watch?v=6zlprE38GGo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In this paper we describe methods to efficiently visualize multiple ntersecting volumetric objects. We introduce the concept of V-Objects. V-Objects represent abstract properties of an object connected to a volumetric data source. We present a method to perform direct volume rendering of a scene comprised of an arbitrary number of possibly intersecting V-Objects. The idea of our approach is to distinguish between regions of intersection, which need costly multi-volume processing, and regions containing only one V-Object, which can be processed using a highly efficient brick-wise volume traversal scheme. Using this method, we achieve significant performance gains for multi-volume rendering. We show possible medical applications, such as surgical planning, diagnosis, and education.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Grimm-2004-MEA.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Grimm-2004-MEA.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Grimm-2004-MEA" class="col-sm-8"> <div class="title">Memory Efficient Acceleration Structures and Techniques for CPU-based Volume Raycasting of Large Data</div> <div class="author"> Sören Grimm, <em>Stefan Bruckner</em>, Armin Kanitsar, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of IEEE VolVis</em>, Oct 2004 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/SVVG.2004.8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Grimm-2004-MEA.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=WK9DJ6Dyrx4,https://www.video.com/watch?v=iYz5VYHMd9U,https://www.video.com/watch?v=UdtaaENWs7M" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Most CPU-based volume raycasting approaches achieve high performance by advanced memory layouts, space subdivision, and excessive pre-computing. Such approaches typically need an enormous amount of memory. They are limited to sizes which do not satisfy the medical data used in daily clinical routine. We present a new volume raycasting approach based on image-ordered raycasting with object-ordered processing, which is able to perform high-quality rendering of very large medical data in real-time on commodity computers. For large medical data such as computed tomographic (CT) angiography run-offs (512x512x1202) we achieve rendering times up to 2.5 fps on a commodity notebook. We achieve this by introducing a memory efficient acceleration technique for on-the-fly gradient estimation and a memory efficient hybrid removal and skipping technique of transparent regions. We employ quantized binary histograms, granular resolution octrees, and a cell invisibility cache. These acceleration structures require just a small extra storage of approximately 10%.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Grimm-2004-RDA.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Grimm-2004-RDA.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Grimm-2004-RDA" class="col-sm-8"> <div class="title">A Refined Data Addressing and Processing Scheme to Accelerate Volume Raycasting</div> <div class="author"> Sören Grimm, <em>Stefan Bruckner</em>, Armin Kanitsar, and Meister Eduard Gröller </div> <div class="periodical"> <em>Computers &amp; Graphics</em>, Oct 2004 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.cag.2004.06.010" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Grimm-2004-RDA.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Most volume rendering systems based on CPU volume raycasting still suffer from inefficient CPU utilization and high memory usage. To target these issues we present a new technique for efficient data addressing. Furthermore, we introduce a new processing scheme for volume raycasting which exploits thread-level parallelism - a technology now supported by commodity computer architectures.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Grimm-2004-VVD.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Grimm-2004-VVD.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Grimm-2004-VVD" class="col-sm-8"> <div class="title">VOTS: VOlume doTS as a Point-Based Representation of Volumetric Data</div> <div class="author"> Sören Grimm, <em>Stefan Bruckner</em>, Armin Kanitsar, and Meister Eduard Gröller </div> <div class="periodical"> <em>Computer Graphics Forum</em>, Sep 2004 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/j.1467-8659..00798.x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Grimm-2004-VVD.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We present Volume dots (Vots), a new primitive for volumetric data modelling, processing, and rendering. Vots are a point-based representation of volumetric data. An individual Vot is specified by the coefficients of a Taylor series expansion, i.e. the function value and higher order derivatives at a specific point. A Vot does not only represent a single sample point, it represents the underlying function within a region. With the Vots representation we have a more intuitive and high-level description of the volume data. This allows direct analytical examination and manipulation of volumetric datasets. Vots enable the representation of the underlying scalar function with specified precision. User-centric importance sampling is also possible, i.e., unimportant volume parts are still present but represented with just very few Vots. As proof of concept, we show Maximum Intensity Projection based on Vots.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2004-EVV-Thesis.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2004-EVV-Thesis.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2004-EVV-Thesis" class="col-sm-8"> <div class="title">Efficient Volume Visualization of Large Medical Datasets</div> <div class="author"> <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>Vienna University of Technology, Austria</em>, May 2004 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Bruckner-2004-EVV-Thesis.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>The size of volumetric datasets used in medical environments is increasing at a rapid pace. Due to excessive pre-computation and memory demanding data structures, most current approaches for volume visualization do not meet the requirements of daily clinical routine. In this diploma thesis, an approach for interactive high-quality rendering of large medical data is presented. It is based on image-order raycasting with object-order data traversal, using an optimized cache coherent memory layout. New techniques and parallelization strategies for direct volume rendering of large data on commodity hardware are presented. By using new memory efficient acceleration data structures, high-quality direct volume rendering of several hundred megabyte sized datasets at sub-second frame rates on a commodity notebook is achieved.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2004-EVV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2004-EVV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2004-EVV" class="col-sm-8"> <div class="title">Efficient Volume Visualization of Large Medical Datasets</div> <div class="author"> <em>Stefan Bruckner</em> </div> <div class="periodical"> <em>In Proceedings of CESCG</em>, Apr 2004 </div> <div class="periodical"> Best Paper Award and Best Presentation Award at CESCG 2004 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Bruckner-2004-EVV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In volume visualization, huge amounts of data have to be processed. While modern hardware is quite capable of this task in terms of processing power, the gap between CPU performance and memory bandwidth further increases with every new generation of CPUs. It is therefore essential to efficiently use the limited memory bandwidth. In this paper, we present novel approaches to optimize CPU-based volume raycasting of large datasets on commodity hardware. A new addressing scheme is introduced, which permits the use of a bricked volume layout with minimal overhead. We further present an extended parallelization strategy for Simultaneous Multithreading. Finally, we introduce memory efficient acceleration data structures which enable us to render large medical datasets, such as the Visible Male (587x341x1878), at up to 2.5 frames/second on a commodity notebook.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2003</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Bruckner-2003-IWN.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Bruckner-2003-IWN.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Bruckner-2003-IWN" class="col-sm-8"> <div class="title">The Inverse Warp: Non-Invasive Integration of Shear-Warp Volume Rendering into Polygon Rendering Pipelines</div> <div class="author"> <em>Stefan Bruckner</em>, Dieter Schmalstieg, Helwig Hauser, and Meister Eduard Gröller </div> <div class="periodical"> <em>In Proceedings of VMV</em>, Nov 2003 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Bruckner-2003-IWN.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.video.com/watch?v=l_49gLBUO3E,https://www.video.com/watch?v=zmWQfUs3Bmc,https://www.video.com/watch?v=qFwv-Ru8Ftc" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In this paper, a simple and efficient solution for combining shear-warp volume rendering and the hardware graphics pipeline is presented. The approach applies an inverse warp transformation to the Z-Buffer, containing the rendered geometry. This information is used for combining geometry and volume data during compositing. We present applications of this concept which include hybrid volume rendering, i.e., concurrent rendering of polygonal objects and volume data, and volume clipping on convex clipping regions. Furthermore, it can be used to efficiently define regions with different rendering modes and transfer functions for focus+context volume rendering. Empirical results show that the approach has very low impact on performance.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Stefan Bruckner. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>